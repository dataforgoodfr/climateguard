{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration of various datasets in the aim of building a CARDS and claim detection dataset.\n",
    "\n",
    "Different steps explored to transform existing datasets to be relevant:\n",
    "- climate-related classification\n",
    "- CARDS classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading binary model: crarojasca/BinaryAugmentedCARDS\n",
      "Loading taxonomy model: crarojasca/TaxonomyAugmentedCARDS\n"
     ]
    }
   ],
   "source": [
    "device=\"cpu\"\n",
    "\n",
    "# Models\n",
    "MAX_LEN = 256\n",
    "BINARY_MODEL_DIR = \"crarojasca/BinaryAugmentedCARDS\"\n",
    "TAXONOMY_MODEL_DIR = \"crarojasca/TaxonomyAugmentedCARDS\"\n",
    "\n",
    "# Loading tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BINARY_MODEL_DIR,\n",
    "    max_length = MAX_LEN, padding = \"max_length\",\n",
    "    return_token_type_ids = True\n",
    ")\n",
    "\n",
    "# Loading Models\n",
    "## 1. Binary Model\n",
    "print(\"Loading binary model: {}\".format(BINARY_MODEL_DIR))\n",
    "config = AutoConfig.from_pretrained(BINARY_MODEL_DIR)\n",
    "binary_model = AutoModelForSequenceClassification.from_pretrained(BINARY_MODEL_DIR, config=config)\n",
    "binary_model.to(device)\n",
    "\n",
    "## 2. Taxonomy Model\n",
    "print(\"Loading taxonomy model: {}\".format(TAXONOMY_MODEL_DIR))\n",
    "config = AutoConfig.from_pretrained(TAXONOMY_MODEL_DIR)\n",
    "taxonomy_model = AutoModelForSequenceClassification.from_pretrained(TAXONOMY_MODEL_DIR, config=config)\n",
    "taxonomy_model.to(device)\n",
    "\n",
    "# Load Dataset\n",
    "id2label = {\n",
    "    0: '1_1', 1: '1_2', 2: '1_3', 3: '1_4', 4: '1_6', 5: '1_7', 6: '2_1',\n",
    "    7: '2_3', 8: '3_1', 9: '3_2', 10: '3_3', 11: '4_1', 12: '4_2', 13: '4_4',\n",
    "    14: '4_5', 15: '5_1', 16: '5_2', 17: '5_3'\n",
    "}\n",
    "\n",
    "# Example:\n",
    "# text = \"Climate change is just a natural phenomenon\"\n",
    "\n",
    "# tokenized_text = tokenizer(text, return_tensors = \"pt\")\n",
    "\n",
    "\n",
    "# # Running Binary Model\n",
    "# outputs = binary_model(**tokenized_text)\n",
    "# binary_score = outputs.logits.softmax(dim = 1)\n",
    "# binary_prediction = torch.argmax(outputs.logits, axis=1)\n",
    "# binary_predictions = binary_prediction.to('cpu').item()\n",
    "\n",
    "# # Running Taxonomy Model\n",
    "# outputs = taxonomy_model(**tokenized_text)\n",
    "# taxonomy_score = outputs.logits.softmax(dim = 1)\n",
    "# taxonomy_prediction = torch.argmax(outputs.logits, axis=1)\n",
    "# taxonomy_prediction = taxonomy_prediction.to('cpu').item()\n",
    "\n",
    "\n",
    "# prediction = \"0_0\" if binary_prediction==0 else id2label[taxonomy_prediction]\n",
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cards(text):\n",
    "  tokenized_text = tokenizer(text, return_tensors = \"pt\")\n",
    "\n",
    "  # Running Binary Model\n",
    "  outputs = binary_model(**tokenized_text)\n",
    "  # binary_score = outputs.logits.softmax(dim = 1)\n",
    "  binary_prediction = torch.argmax(outputs.logits, axis=1)\n",
    "  binary_prediction = binary_prediction.to('cuda').item()\n",
    "\n",
    "  if binary_prediction == 0:\n",
    "    return \"0_0\"\n",
    "  # Running Taxonomy Model\n",
    "  outputs = taxonomy_model(**tokenized_text)\n",
    "  # taxonomy_score = outputs.logits.softmax(dim = 1)\n",
    "  taxonomy_prediction = torch.argmax(outputs.logits, axis=1)\n",
    "  taxonomy_prediction = taxonomy_prediction.to('cuda').item()\n",
    "\n",
    "  return id2label[taxonomy_prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate-fever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3dd77fba92491cb5aff9538f94a42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58871b28c0cc4abca00f6647be09960a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/869k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34595e1eee764b3cb68cc0a533bb8d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading\n",
    "ds_climate_fever = load_dataset(\"tdiggelm/climate_fever\")\n",
    "df = ds_climate_fever[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cards prediction\n",
    "df['cards_label_predicted'] = df['claim'].apply(lambda x: predict_cards(x))\n",
    "\n",
    "df[\"cards_label\"] = df.apply(lambda row: 0 if row['claim_label'] == 0 else None,axis=1)\n",
    "df_to_label = df[df['cards_label'].isna()]\n",
    "df_to_label.to_csv(\"../../data/exploration/cards-fever_to_label.csv\", index=False)\n",
    "\n",
    "df.cards_label_predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cards_label_predicted\n",
       "0_0    911\n",
       "5_2    407\n",
       "5_1    169\n",
       "5_3     44\n",
       "3_2      2\n",
       "3_3      1\n",
       "1_3      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_label.to_csv(\"../../data/exploration/cards-fever_to_label.csv\", index=False)\n",
    "\n",
    "df.cards_label_predicted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CARDS classification models are over-predicting the 5th category, as they are prominent in the original CARDS twitter dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cards dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O sample_data/dataset_cards \"https://drive.google.com/uc?export=download&id=14exmlYCT3-K2byYHFFrShAIYiemJQroi\"\n",
    "!unzip sample_data/dataset_cards.zip -d sample_data/cards_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cards_label\"] = df.apply(lambda row: 0 if row['claim_label'] == 0 else None,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate-related classification\n",
    "\n",
    "Using climatebert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "import datasets\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "dataset_name = \"climatebert/climate_detection\"\n",
    "model_name = \"climatebert/distilroberta-base-climate-detector\"\n",
    "\n",
    "# If you want to use your own data, simply load them as ðŸ¤— Datasets dataset, see https://huggingface.co/docs/datasets/loading\n",
    "# dataset = datasets.load_dataset(dataset_name, split=\"test\")\n",
    "\n",
    "model_cbert = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer_cbert = AutoTokenizer.from_pretrained(model_name, max_len=512)\n",
    "model_cbert.to(\"cuda\")\n",
    "\n",
    "def predict_env(text):\n",
    "  tokenized_text = tokenizer_cbert(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "  outputs = model_cbert(**tokenized_text)\n",
    "  pred = torch.argmax(outputs.logits, axis=1)\n",
    "  pred = pred.to(\"cpu\").item()\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing recall on climate-fever (which is supposed to be 100% climate-related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds_climate_fever[\"test\"].to_pandas()\n",
    "df = df.sample(100)\n",
    "df[\"prediction_env\"] = df.claim.apply(lambda x: predict_env(x))\n",
    "df.to_csv(\"../data/exploration/climate-fever-env-prediction.csv\",index=False)\n",
    "\n",
    "print(\"NON CLIMATE RELATED\")\n",
    "for x in df[df[\"prediction_env\"]==0].claim:\n",
    "  print(x)\n",
    "\n",
    "print(\"CLIMATE RELATED\")\n",
    "for x in df[df[\"prediction_env\"]==1].sample(30).claim:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering datasets to find climate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -O sample_data/claimbuster.zip \"https://drive.google.com/uc?export=download&id=14exmlYCT3-K2byYHFFrShAIYiemJQroi\"\n",
    "!unzip drive/MyDrive/datasets/MultiFC_Codalab/scoring_multifc.zip -d drive/MyDrive/datasets/MultiFC_Codalab/scoring_multifc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../datasets/MultiFC_Codalab/public_data/dev.tsv\", sep='\\t', header=None)\n",
    "df.columns = ['claimID', 'claim', 'label', 'claim_url', \"reason\", \"category\", \"speaker\",\"checker\", \"tags\",\"title\",\"publish_date\", \"claim_date\", \"claim_entities\"]\n",
    "print(df.size)\n",
    "df = df.dropna(subset=['claim'])\n",
    "df = df[df['claim'].str.len() <= 512]\n",
    "print(df.size)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "for x in df.tags.unique():\n",
    "  if not isinstance(x, str):\n",
    "    continue\n",
    "  values = x[1:-1].split(\",\")\n",
    "  values = [v.replace(\"'\",\"\").strip() for v in values]\n",
    "  tags.extend(values)\n",
    "\n",
    "tags = list(set(tags))\n",
    "tags.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "for value in df.claim_date\n",
    "tags = df.claim_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"detecting climate related...\")\n",
    "df[\"env_predict\"] = df.progress_apply(lambda x: predict_env(x[\"claim\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_claims = df[df.env_predict == 1]\n",
    "\n",
    "env_claims.to_csv(\"/content/drive/MyDrive/results/multiFC_env_claims.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
