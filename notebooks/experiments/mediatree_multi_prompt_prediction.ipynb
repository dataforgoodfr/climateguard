{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185738, 10)\n",
      "(3022, 10)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../../data/18_channels_2023_09_to_2024_09.parquet\")\n",
    "print(df.shape)\n",
    "df.start = pd.to_datetime(df.start)\n",
    "cutoff = df.start.max() - pd.Timedelta(days=21)\n",
    "df = df[df.start >= cutoff]\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    185738.000000\n",
       "mean       2136.974200\n",
       "std         435.559148\n",
       "min          76.000000\n",
       "25%        1966.000000\n",
       "50%        2229.000000\n",
       "75%        2419.000000\n",
       "max        3891.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    185738.00000\n",
       "mean        473.80472\n",
       "std          97.39974\n",
       "min          26.00000\n",
       "25%         433.00000\n",
       "50%         493.00000\n",
       "75%         537.00000\n",
       "max         827.00000\n",
       "Name: num_tokens, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "channel_is_radio\n",
       "False    109739\n",
       "True      75999\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "channel_program_type\n",
       "Information en continu            113094\n",
       "Information - Magazine             47678\n",
       "Information - Journal              21401\n",
       "Information - Autres émissions      3565\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.text.str.len().describe())\n",
    "display(df.num_tokens.describe())\n",
    "\n",
    "display(df.channel_is_radio.value_counts())\n",
    "display(df.channel_program_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "from litellm import acompletion, completion_cost\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Callable, Awaitable, Union\n",
    "from functools import wraps\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "\n",
    "class MediatreePrediction(BaseModel):\n",
    "    cards_label_pred: str\n",
    "    prompt_tokens: int\n",
    "    completion_tokens: int\n",
    "    total_tokens: int\n",
    "    cost: float\n",
    "    claim_pred: str | None = None\n",
    "\n",
    "\n",
    "class MediatreeClaimIdentifier(BaseModel):\n",
    "    claim: str = Field(\n",
    "        description=\"Reformulation courte et claire de l'affirmation à vérifier\"\n",
    "    )\n",
    "    context: str = Field(\n",
    "        description=\"Un seul paragraphe résumant le contexte essentiel pour comprendre l'affirmation\"\n",
    "    )\n",
    "    quote: str = Field(description=\"Citation exacte du texte contenant l'affirmation\")\n",
    "\n",
    "\n",
    "class MediatreeClaimIdentifierResponse(BaseModel):\n",
    "    claims: Union[list[MediatreeClaimIdentifier], None]\n",
    "    prompt_tokens: Union[int, None]\n",
    "    completion_tokens: Union[int, None]\n",
    "    total_tokens: Union[int, None]\n",
    "    cost: Union[float, None]\n",
    "\n",
    "\n",
    "async def report_experiment_results(\n",
    "    df: pd.DataFrame, predict_experiment: Callable[[str], Awaitable[None]]\n",
    ") -> None:\n",
    "    # Copy df to avoid modifications\n",
    "    df = df.copy()\n",
    "\n",
    "    # Run the experiment\n",
    "    mediatree_predictions: list[MediatreeClaimIdentifierResponse] = await tqdm.gather(\n",
    "        *[predict_experiment(text) for text in df[\"text\"]]\n",
    "    )\n",
    "    # Create lists to store individual claims and their metadata\n",
    "    rows = []\n",
    "    \n",
    "    for idx, pred in zip(df.index, mediatree_predictions):\n",
    "        if pred is not None and pred.claims is not None:\n",
    "            for claim in pred.claims:\n",
    "                rows.append({\n",
    "                    'id': idx,\n",
    "                    'claim': claim.claim,\n",
    "                    'context': claim.context,\n",
    "                    'quote': claim.quote,\n",
    "                    'prompt_tokens': pred.prompt_tokens,\n",
    "                    'completion_tokens': pred.completion_tokens,\n",
    "                    'total_tokens': pred.total_tokens,\n",
    "                    'cost': pred.cost\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame with one claim per row\n",
    "    mediatree_predictions_df = pd.DataFrame(rows)\n",
    "    \n",
    "    if not mediatree_predictions_df.empty:\n",
    "        # Set id as index if there are any claims\n",
    "        mediatree_predictions_df = mediatree_predictions_df.set_index('id')\n",
    "    # df = pd.concat([df, mediatree_predictions_df], axis=1)\n",
    "    df = df.merge(mediatree_predictions_df, left_index=True, right_index=True, how=\"outer\")\n",
    "\n",
    "    # Show stats and performance\n",
    "    show_llm_usage(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def show_llm_usage(df: pd.DataFrame) -> None:\n",
    "    print(\"\\nLLM USAGE\\n=========\\n\")\n",
    "    print(\n",
    "        f\"Median token usage:\\n- Prompt: {int(df[\"prompt_tokens\"].median())}\\n\"\n",
    "        f\"- Completion: {int(df[\"completion_tokens\"].median())}\\n\"\n",
    "        f\"- Total: {int(df[\"total_tokens\"].median())}\"\n",
    "    )\n",
    "    print(f\"\\nTotal cost: ${df[\"cost\"].sum():.3f}\\n\")\n",
    "\n",
    "\n",
    "# Limit concurrent requests to avoid API rate limiting\n",
    "# (it depends on the model you use and your API tier)\n",
    "semaphore = asyncio.Semaphore(5)\n",
    "\n",
    "\n",
    "# Decorator that ensures `acompletion` uses the semaphore\n",
    "def with_semaphore(acquire_semaphore):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        async def wrapper(*args, **kwargs):\n",
    "            async with acquire_semaphore:\n",
    "                return await func(*args, **kwargs)\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "acompletion = with_semaphore(semaphore)(acompletion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:31<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM USAGE\n",
      "=========\n",
      "\n",
      "Median token usage:\n",
      "- Prompt: 740\n",
      "- Completion: 295\n",
      "- Total: 1044\n",
      "\n",
      "Total cost: $0.038\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "async def say(text, sec):\n",
    "    await asyncio.sleep(sec)\n",
    "    print(text)\n",
    "\n",
    "\n",
    "async def extract_claims(text: str) -> MediatreeClaimIdentifierResponse:\n",
    "    system_prompt = \"\"\"\n",
    "Tu es un assistant spécialisé dans l'analyse de désinformation environnementale.\n",
    "\n",
    "TÂCHE:\n",
    "Analyse l'extrait de transcription TV/Radio fourni et identifie les affirmations (claims) qui nécessitent une vérification factuelle sur les thèmes suivants:\n",
    "- Changement climatique\n",
    "- Transition écologique\n",
    "- Énergie\n",
    "- Biodiversité\n",
    "- Pollution\n",
    "- Pesticides\n",
    "- Ressources naturelles (eau, minéraux, etc.)\n",
    "\n",
    "FORMAT DE RÉPONSE:\n",
    "Tu dois OBLIGATOIREMENT répondre au format JSON suivant:\n",
    "{\n",
    "    \"claims\": [\n",
    "        {\n",
    "            \"claim\": \"Reformulation courte et claire de l'affirmation à vérifier\",\n",
    "            \"context\": \"Un seul paragraphe résumant le contexte essentiel pour comprendre l'affirmation\",\n",
    "            \"quote\": \"Citation exacte du texte contenant l'affirmation\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "RÈGLES IMPORTANTES:\n",
    "1. Inclure UNIQUEMENT les affirmations vérifiables sur les thèmes environnementaux\n",
    "2. Chaque claim doit être unique\n",
    "3. Le format JSON doit être strictement respecté\n",
    "4. Si aucune affirmation à vérifier n'est trouvée, renvoyer un tableau claims vide\n",
    "5. Maximum 3 claims par analyse\n",
    "\n",
    "Analyse maintenant le texte suivant:\"\"\"\n",
    "    response = await acompletion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": text.strip()},\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0,\n",
    "    )\n",
    "    claim_identifier = response.choices[0].message.content\n",
    "    claims = (\n",
    "        [\n",
    "            MediatreeClaimIdentifier(**claim)\n",
    "            for claim in json.loads(claim_identifier)[\"claims\"]\n",
    "        ]\n",
    "        if json.loads(claim_identifier)[\"claims\"] != []\n",
    "        else None\n",
    "    )\n",
    "    return (\n",
    "        MediatreeClaimIdentifierResponse(\n",
    "            claims=claims,\n",
    "            prompt_tokens=response.usage.prompt_tokens,\n",
    "            completion_tokens=response.usage.completion_tokens,\n",
    "            total_tokens=response.usage.total_tokens,\n",
    "            cost=completion_cost(response),\n",
    "        )\n",
    "        if claims is not None\n",
    "        else None\n",
    "    )\n",
    "\n",
    "\n",
    "claim_detections = await report_experiment_results(df.iloc[:100], extract_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "claim_detections.to_csv(\"../../data/claim_detections_video_extractions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
