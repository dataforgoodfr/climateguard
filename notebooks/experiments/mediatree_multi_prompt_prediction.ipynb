{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39131, 11)\n",
      "(39131, 11)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../../data/raw/4_channels_predictions_09_2023_09_2024.parquet\")\n",
    "print(df.shape)\n",
    "df.start = pd.to_datetime(df.start)\n",
    "cutoff = df.start.max() - pd.Timedelta(days=21)\n",
    "# df = df[df.start >= cutoff]\n",
    "# df = df.loc[(df.start >= pd.to_datetime(\"2023-12-01\")) & (df.start <= pd.to_datetime(\"2024-06-01\"))]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39131.000000\n",
       "mean      2118.706882\n",
       "std        412.775075\n",
       "min        122.000000\n",
       "25%       1930.000000\n",
       "50%       2203.000000\n",
       "75%       2399.000000\n",
       "max       3869.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    39131.000000\n",
       "mean       473.946973\n",
       "std         93.818349\n",
       "min         30.000000\n",
       "25%        430.000000\n",
       "50%        493.000000\n",
       "75%        537.500000\n",
       "max        827.000000\n",
       "Name: num_tokens, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "channel_is_radio\n",
       "False    23725\n",
       "True     15406\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "channel_program_type\n",
       "Information en continu    19107\n",
       "Information - Magazine    17420\n",
       "Information - Journal      2604\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.text.str.len().describe())\n",
    "display(df.num_tokens.describe())\n",
    "\n",
    "display(df.channel_is_radio.value_counts())\n",
    "display(df.channel_program_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "from litellm import acompletion, completion_cost\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Callable, Awaitable, Union\n",
    "from functools import wraps\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "\n",
    "class MediatreePrediction(BaseModel):\n",
    "    cards_label_pred: str\n",
    "    prompt_tokens: int\n",
    "    completion_tokens: int\n",
    "    total_tokens: int\n",
    "    cost: float\n",
    "    claim_pred: str | None = None\n",
    "\n",
    "\n",
    "class MediatreeClaimIdentifier(BaseModel):\n",
    "    context: str = Field(\n",
    "        description=\"la phrase/paragraphe qui contient le contexte general\"\n",
    "    )\n",
    "    quote: str = Field(description=\"Citation exacte du texte contenant l'affirmation\")\n",
    "\n",
    "\n",
    "class MediatreeClaimIdentifierResponse(BaseModel):\n",
    "    claims: Union[list[MediatreeClaimIdentifier], None]\n",
    "    prompt_tokens: Union[int, None]\n",
    "    completion_tokens: Union[int, None]\n",
    "    total_tokens: Union[int, None]\n",
    "    cost: Union[float, None]\n",
    "\n",
    "\n",
    "async def report_experiment_results(\n",
    "    df: pd.DataFrame, predict_experiment: Callable[[str], Awaitable[None]]\n",
    ") -> None:\n",
    "    # Copy df to avoid modifications\n",
    "    df = df.copy()\n",
    "\n",
    "    # Run the experiment\n",
    "    mediatree_predictions: list[MediatreeClaimIdentifierResponse] = await tqdm.gather(\n",
    "        *[predict_experiment(text) for text in df[\"text\"]]\n",
    "    )\n",
    "    # Create lists to store individual claims and their metadata\n",
    "    rows = []\n",
    "\n",
    "    for idx, pred in zip(df.index, mediatree_predictions):\n",
    "        if pred is not None and pred.claims is not None:\n",
    "            for claim in pred.claims:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"id\": idx,\n",
    "                        \"context\": claim.context,\n",
    "                        \"quote\": claim.quote,\n",
    "                        \"prompt_tokens\": pred.prompt_tokens,\n",
    "                        \"completion_tokens\": pred.completion_tokens,\n",
    "                        \"total_tokens\": pred.total_tokens,\n",
    "                        \"cost\": pred.cost,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    # Create DataFrame with one claim per row\n",
    "    mediatree_predictions_df = pd.DataFrame(rows)\n",
    "\n",
    "    if not mediatree_predictions_df.empty:\n",
    "        # Set id as index if there are any claims\n",
    "        mediatree_predictions_df = mediatree_predictions_df.set_index(\"id\")\n",
    "    # df = pd.concat([df, mediatree_predictions_df], axis=1)\n",
    "    df = df.merge(\n",
    "        mediatree_predictions_df, left_index=True, right_index=True, how=\"outer\"\n",
    "    )\n",
    "\n",
    "    # Show stats and performance\n",
    "    show_llm_usage(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def show_llm_usage(df: pd.DataFrame) -> None:\n",
    "    print(\"\\nLLM USAGE\\n=========\\n\")\n",
    "    print(\n",
    "        f\"Median token usage:\\n- Prompt: {int(df[\"prompt_tokens\"].median())}\\n\"\n",
    "        f\"- Completion: {int(df[\"completion_tokens\"].median())}\\n\"\n",
    "        f\"- Total: {int(df[\"total_tokens\"].median())}\"\n",
    "    )\n",
    "    print(f\"\\nTotal cost: ${df[\"cost\"].sum():.3f}\\n\")\n",
    "\n",
    "\n",
    "# Limit concurrent requests to avoid API rate limiting\n",
    "# (it depends on the model you use and your API tier)\n",
    "semaphore = asyncio.Semaphore(40)\n",
    "\n",
    "\n",
    "# Decorator that ensures `acompletion` uses the semaphore\n",
    "def with_semaphore(acquire_semaphore):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        async def wrapper(*args, **kwargs):\n",
    "            async with acquire_semaphore:\n",
    "                return await func(*args, **kwargs)\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "acompletion = with_semaphore(semaphore)(acompletion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [03:02<00:00, 27.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM USAGE\n",
      "=========\n",
      "\n",
      "Median token usage:\n",
      "- Prompt: 1028\n",
      "- Completion: 224\n",
      "- Total: 1251\n",
      "\n",
      "Total cost: $0.433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "async def extract_claims(text: str) -> MediatreeClaimIdentifierResponse:\n",
    "    system_prompt = \"\"\"\n",
    "Tu es un assistant spécialisé dans l'analyse de désinformation environnementale.\n",
    "\n",
    "TÂCHE:\n",
    "Analyse l'extrait de transcription TV/Radio fourni et identifie les affirmations (claims) qui nécessitent une vérification factuelle sur les thèmes suivants:\n",
    "- Changement climatique\n",
    "- Transition écologique\n",
    "- Énergie\n",
    "- Biodiversité\n",
    "- Pollution\n",
    "- Pesticides\n",
    "- Ressources naturelles (eau, minéraux, etc.)\n",
    "- Sort la quote seulement si t'est sure qu'elle continent de la désinformation environnementale/climatique.\n",
    "- Avec le quote il faute sortire le paragraphe qui contient le contexte general utilisant du texte avant et apres le quote. AU MOINS DEUX PHRASES.\n",
    "- Pour exemple, le suivant texte:\n",
    "\"Merci monsieur Dupont, en fait je ne suis pas d'accord avec vous. Si on regard les dèrnieres jours, en France il fait plus froid que d'abitude ! Il y a pas de signes du rechauffement climatique !\"\n",
    "\n",
    "La quote est: \"Il y a pas de signes du rechauffement climatique !\"\n",
    "Et le context est: \"Si on regard les dèrnieres jours, en France il fait plus froid que d'abitude ! Il y a pas de signes du rechauffement climatique !\"\n",
    "\n",
    "FORMAT DE RÉPONSE:\n",
    "Tu dois OBLIGATOIREMENT répondre au format JSON suivant:\n",
    "{\n",
    "    \"claims\": [\n",
    "        {\n",
    "            \"context\": \"Un seul paragraphe résumant le contexte essentiel pour comprendre l'affirmation\",\n",
    "            \"quote\": \"l'extrait de texte culpable de desinformation\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "RÈGLES IMPORTANTES:\n",
    "1. Inclure UNIQUEMENT les affirmations vérifiables sur les thèmes environnementaux contenant de la désinformation environnementale/climatique\n",
    "2. Chaque claim doit être unique\n",
    "3. Le format JSON doit être strictement respecté\n",
    "4. Si aucune affirmation à vérifier n'est trouvée, renvoyer les claims comme un json vide {\"claims\": []}\n",
    "5. Maximum 3 claims par analyse\n",
    "6. La quote doit être exactement la meme que dans le texte, et concener que la phrase incriminée.\n",
    "7. Le context doit être une paragraphe extrait et pas re-elaboré contenant la quote, contenant du texte avant et apres le quote. AU MOINS DEUX PHRASES.\n",
    "\n",
    "Analyse maintenant le texte suivant:\n",
    "\n",
    "\"\"\"\n",
    "    response = await acompletion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": text.strip()},\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0.01,\n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "    claim_identifier = response.choices[0].message.content\n",
    "    claims = (\n",
    "        [\n",
    "            MediatreeClaimIdentifier(**claim)\n",
    "            for claim in json.loads(claim_identifier)[\"claims\"]\n",
    "        ]\n",
    "        if json.loads(claim_identifier)[\"claims\"] != []\n",
    "        else None\n",
    "    )\n",
    "    return (\n",
    "        MediatreeClaimIdentifierResponse(\n",
    "            claims=claims,\n",
    "            prompt_tokens=response.usage.prompt_tokens,\n",
    "            completion_tokens=response.usage.completion_tokens,\n",
    "            total_tokens=response.usage.total_tokens,\n",
    "            cost=completion_cost(response),\n",
    "        )\n",
    "        if claims is not None\n",
    "        else None\n",
    "    )\n",
    "\n",
    "\n",
    "claim_detections = await report_experiment_results(df.iloc[:5000], extract_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5274 entries, 000cd7d6be597f6a569a45803f2648b8d096c4c7153a7e98ea63f0e827474f8a to fffc87c2d670e5368f1a5e0f43a430c4fdf99bf5042f1c9c3ea7ec9b08f8490e\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   start                 5274 non-null   datetime64[ns]\n",
      " 1   text                  5274 non-null   object        \n",
      " 2   channel_name          5274 non-null   object        \n",
      " 3   channel_is_radio      5274 non-null   bool          \n",
      " 4   channel_program_type  5274 non-null   object        \n",
      " 5   channel_program       5274 non-null   object        \n",
      " 6   themes                5274 non-null   object        \n",
      " 7   keywords              5274 non-null   object        \n",
      " 8   num_keywords          5274 non-null   int64         \n",
      " 9   num_tokens            5274 non-null   int64         \n",
      " 10  claims                5274 non-null   object        \n",
      " 11  context               1415 non-null   object        \n",
      " 12  quote                 1415 non-null   object        \n",
      " 13  prompt_tokens         1415 non-null   float64       \n",
      " 14  completion_tokens     1415 non-null   float64       \n",
      " 15  total_tokens          1415 non-null   float64       \n",
      " 16  cost                  1415 non-null   float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(4), int64(2), object(9)\n",
      "memory usage: 705.6+ KB\n"
     ]
    }
   ],
   "source": [
    "claim_detections.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_detections = claim_detections.dropna(subset=[\"context\", \"quote\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1415, 17)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim_detections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>quote</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000cd7d6be597f6a569a45803f2648b8d096c4c7153a7e98ea63f0e827474f8a</th>\n",
       "      <td>Les fortes pluies de cet automne ont fait débo...</td>\n",
       "      <td>avec le réchauffement climatique on va avoir d...</td>\n",
       "      <td>un charles guyard arrivent au pire moment comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6ca7d1e8a22efed7bf0</th>\n",
       "      <td>Il est surveillé par satellite pour savoir com...</td>\n",
       "      <td>l'agriculture et je le cite une catastrophe hu...</td>\n",
       "      <td>capitalisme et le libre marché des normes envi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6ca7d1e8a22efed7bf0</th>\n",
       "      <td>Alors l'écrivaine du monde paysan marie-hélène...</td>\n",
       "      <td>ils veulent la décroissance mais sans en assum...</td>\n",
       "      <td>capitalisme et le libre marché des normes envi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005ff4ddbceb67699166e6e785ef77df468b2ff8162f1d44e5630e1d7a2b5977</th>\n",
       "      <td>Alors que la zone b termine ses vacances d'hiv...</td>\n",
       "      <td>la crise climatique</td>\n",
       "      <td>les offres en cours conditions en magasin ou s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00919bd64439601cc4584384cf3f0f61045f4629560b7def73c833f59fca662d</th>\n",
       "      <td>Christophe Béchu, le ministre de la transition...</td>\n",
       "      <td>vous auriez pu faire exactement la même interv...</td>\n",
       "      <td>les interviews qui qu'il a donné un depuis deu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fee7f2aae94f499a2466a2e0555d199dc0595cf88fdf68bf34990576ab70eca5</th>\n",
       "      <td>alors il y a au moins une annonce qui semble s...</td>\n",
       "      <td>abandon du no du principal indicateur utilisé ...</td>\n",
       "      <td>avant leur évacuation par les crs à saint-quen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff072840e917a5764089d0f56b67cd0fe0dbe7c760d9ad67071fe1d440da046c</th>\n",
       "      <td>sécheresse exceptionnelle qui faisait que les ...</td>\n",
       "      <td>les barrages étaient vides</td>\n",
       "      <td>sécheresse exceptionnelle qui faisait que les ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff072840e917a5764089d0f56b67cd0fe0dbe7c760d9ad67071fe1d440da046c</th>\n",
       "      <td>il faut rester toujours vigilants c'est pour ç...</td>\n",
       "      <td>les barrages sont pleins</td>\n",
       "      <td>sécheresse exceptionnelle qui faisait que les ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff0fe9f038a9ee3e214cb4d126b51df619b490311a04333d83a6c43b7ee884ce</th>\n",
       "      <td>Il y a un embargo sur le ring en ce moment et ...</td>\n",
       "      <td>il y a des sécheresses ou à des inondations qu...</td>\n",
       "      <td>petit bonheur la chance au petit bonheur la ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff412f24dbb52456654d80a50166df731c603e4c8bedac928c284ccef5d94c25</th>\n",
       "      <td>le papier toilette et responsable de quinze po...</td>\n",
       "      <td>le papier toilette et responsable de quinze po...</td>\n",
       "      <td>la chasse aux oisifs vous êtes bien informé ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1415 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              context  \\\n",
       "id                                                                                                      \n",
       "000cd7d6be597f6a569a45803f2648b8d096c4c7153a7e9...  Les fortes pluies de cet automne ont fait débo...   \n",
       "004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6c...  Il est surveillé par satellite pour savoir com...   \n",
       "004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6c...  Alors l'écrivaine du monde paysan marie-hélène...   \n",
       "005ff4ddbceb67699166e6e785ef77df468b2ff8162f1d4...  Alors que la zone b termine ses vacances d'hiv...   \n",
       "00919bd64439601cc4584384cf3f0f61045f4629560b7de...  Christophe Béchu, le ministre de la transition...   \n",
       "...                                                                                               ...   \n",
       "fee7f2aae94f499a2466a2e0555d199dc0595cf88fdf68b...  alors il y a au moins une annonce qui semble s...   \n",
       "ff072840e917a5764089d0f56b67cd0fe0dbe7c760d9ad6...  sécheresse exceptionnelle qui faisait que les ...   \n",
       "ff072840e917a5764089d0f56b67cd0fe0dbe7c760d9ad6...  il faut rester toujours vigilants c'est pour ç...   \n",
       "ff0fe9f038a9ee3e214cb4d126b51df619b490311a04333...  Il y a un embargo sur le ring en ce moment et ...   \n",
       "ff412f24dbb52456654d80a50166df731c603e4c8bedac9...  le papier toilette et responsable de quinze po...   \n",
       "\n",
       "                                                                                                quote  \\\n",
       "id                                                                                                      \n",
       "000cd7d6be597f6a569a45803f2648b8d096c4c7153a7e9...  avec le réchauffement climatique on va avoir d...   \n",
       "004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6c...  l'agriculture et je le cite une catastrophe hu...   \n",
       "004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6c...  ils veulent la décroissance mais sans en assum...   \n",
       "005ff4ddbceb67699166e6e785ef77df468b2ff8162f1d4...                                la crise climatique   \n",
       "00919bd64439601cc4584384cf3f0f61045f4629560b7de...  vous auriez pu faire exactement la même interv...   \n",
       "...                                                                                               ...   \n",
       "fee7f2aae94f499a2466a2e0555d199dc0595cf88fdf68b...  abandon du no du principal indicateur utilisé ...   \n",
       "ff072840e917a5764089d0f56b67cd0fe0dbe7c760d9ad6...                         les barrages étaient vides   \n",
       "ff072840e917a5764089d0f56b67cd0fe0dbe7c760d9ad6...                           les barrages sont pleins   \n",
       "ff0fe9f038a9ee3e214cb4d126b51df619b490311a04333...  il y a des sécheresses ou à des inondations qu...   \n",
       "ff412f24dbb52456654d80a50166df731c603e4c8bedac9...  le papier toilette et responsable de quinze po...   \n",
       "\n",
       "                                                                                                 text  \n",
       "id                                                                                                     \n",
       "000cd7d6be597f6a569a45803f2648b8d096c4c7153a7e9...  un charles guyard arrivent au pire moment comm...  \n",
       "004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6c...  capitalisme et le libre marché des normes envi...  \n",
       "004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6c...  capitalisme et le libre marché des normes envi...  \n",
       "005ff4ddbceb67699166e6e785ef77df468b2ff8162f1d4...  les offres en cours conditions en magasin ou s...  \n",
       "00919bd64439601cc4584384cf3f0f61045f4629560b7de...  les interviews qui qu'il a donné un depuis deu...  \n",
       "...                                                                                               ...  \n",
       "fee7f2aae94f499a2466a2e0555d199dc0595cf88fdf68b...  avant leur évacuation par les crs à saint-quen...  \n",
       "ff072840e917a5764089d0f56b67cd0fe0dbe7c760d9ad6...  sécheresse exceptionnelle qui faisait que les ...  \n",
       "ff072840e917a5764089d0f56b67cd0fe0dbe7c760d9ad6...  sécheresse exceptionnelle qui faisait que les ...  \n",
       "ff0fe9f038a9ee3e214cb4d126b51df619b490311a04333...  petit bonheur la chance au petit bonheur la ch...  \n",
       "ff412f24dbb52456654d80a50166df731c603e4c8bedac9...  la chasse aux oisifs vous êtes bien informé ex...  \n",
       "\n",
       "[1415 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim_detections[[\"context\", \"quote\", \"text\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_detections[[\"context\", \"quote\", \"text\"]].to_csv(\"../../data/processed/claim_detections_video_extractions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "914"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "INSTRUCTION_PROMPT = \"\"\"You are an expert in disinformation on environmental and climate subjects, expert in climate science and know everything about the GIEC. I am going to give you series of claims coming from quotes on medias. Among these, some will contain climate disinformation. Your task is to find disinformation claim if they exist, and classify them following the pre-defined categories.\n",
    "\n",
    "You must respond with a JSON object containing one field:\n",
    "- \"category\": the classification label\n",
    "\n",
    "<categories>\n",
    "- \"0_accepted\": No relevant environmental disinformation claim detected.\n",
    "- \"1_not_happening\": Global warming is not happing. Climate change is NOT leading to melting ice (such as glaciers, sea ice, and permafrost), increased extreme weather, or rising sea levels. Cold weather also shows that climate change is not happening.\n",
    "- \"2_not_human\": Greenhouse gases from humans are not the causing climate change.\n",
    "- \"3_not_bad\": The impacts of climate change will not be bad and might even be beneficial.\n",
    "- \"4_solutions_wont_work\": Climate solutions are harmful or unnecessary.\n",
    "- \"5_science_is_unreliable\": Climate science is uncertain, unsound, unreliable, or biased.\n",
    "- \"6_scientists_are_biased\": Climate scientists and proponents of climate action are alarmist, biased, wrong, hypocritical, corrupt, and/or politically motivated.\n",
    "- \"7_need_fossil_fuel\": We need fossil fuels for economic growth, prosperity, and to maintain our standard of living.\n",
    "</categories>\n",
    "\"\"\"\n",
    "\n",
    "EXAMPLES_PROMPT = \"\"\"\n",
    "<examples>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "A warmer planet will actually be good for agriculture—more CO2 means bigger crops and longer growing seasons!\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "more CO2 means bigger crops and longer growing seasons!\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"3_not_bad\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "The data is clear: the Earth is warming due to human activities, and immediate action is required to mitigate its effects.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "the Earth is warming due to human activities, and immediate action is required to mitigate its effects.\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"0_accepted\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "Global warming is just a myth pushed by elites—if the planet were really heating up, why did we just have the coldest winter in decades?\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "Global warming is just a myth pushed by elites\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"1_not_happening\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "These so-called climate experts are just chasing grant money, hyping up fear to keep their funding flowing.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "climate experts are just chasing grant money\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"6_scientists_are_biased\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "Climate models have been wrong so many times; why should we trust them now? They're just guesses based on incomplete data.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "Climate models have been wrong so many times\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"5_science_is_unreliable\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "Climate has always changed naturally throughout history; blaming humans for it is absurd and ignores natural cycles like solar activity.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "Climate has always changed naturally throughout history\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"2_not_human\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "Switching to renewable energy will cripple our economy without making any real difference to the planet's temperature.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "Switching to renewable energy will cripple our economy\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"4_solutions_wont_work\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "Without fossil fuels, our society would collapse—we can't power modern civilization on wind turbines and solar panels alone.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "Without fossil fuels, our society would collapse\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"7_need_fossil_fuel\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "</examples>\"\"\"\n",
    "\n",
    "FEW_SHOT_PROMPT = INSTRUCTION_PROMPT + EXAMPLES_PROMPT\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "len(encoding.encode(FEW_SHOT_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "Extract to analyze:\n",
    "<extract>\n",
    "{context}\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "{quote}\n",
    "</highlighted_quote>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MediatreeClaimCardsClassification(BaseModel):\n",
    "    category: str = Field(\n",
    "        description=\"Label of the disinformation type\"\n",
    "    )\n",
    "\n",
    "\n",
    "async def classify(\n",
    "    system_prompt: str, user_prompt: str\n",
    ") -> MediatreeClaimCardsClassification:\n",
    "    response = await acompletion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.01,\n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "    claim_validity = response.choices[0].message.content\n",
    "    return MediatreeClaimCardsClassification(**json.loads(claim_validity))\n",
    "\n",
    "\n",
    "async def classify_claims(claims_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    claim_classifications: list[MediatreeClaimCardsClassification] = await tqdm.gather(\n",
    "        *[\n",
    "            classify(\n",
    "                FEW_SHOT_PROMPT,\n",
    "                USER_PROMPT_TEMPLATE.format(\n",
    "                    context=claim.context, quote=claim.quote\n",
    "                ),\n",
    "            )\n",
    "            for claim in claims_df.itertuples()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    claim_classifications_df = pd.DataFrame(\n",
    "        [classification.model_dump(exclude_none=True) for classification in claim_classifications],\n",
    "        index=claims_df.index,\n",
    "    )\n",
    "\n",
    "    claim_classifications_df = pd.concat([claims_df, claim_classifications_df], axis=1)\n",
    "\n",
    "    return claim_classifications_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1415/1415 [00:29<00:00, 47.92it/s]\n"
     ]
    }
   ],
   "source": [
    "classified_claims_df = await classify_claims(claim_detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "0_accepted                 1144\n",
       "4_solutions_wont_work       138\n",
       "1_not_happening              66\n",
       "5_science_is_unreliable      24\n",
       "3_not_bad                    14\n",
       "2_not_human                  12\n",
       "6_scientists_are_biased      11\n",
       "7_need_fossil_fuel            6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_claims_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_group\n",
       "No disinformation    1144\n",
       "Inaction              155\n",
       "Disinformation        116\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "classified_claims_df[\"category_group\"] = \"No disinformation\"\n",
    "classified_claims_df[\"category_group\"] = np.where(classified_claims_df.category.isin([\"1_not_happening\", \"2_not_human\", \"3_not_bad\", \"5_science_is_unreliable\"]), \"Disinformation\", classified_claims_df[\"category_group\"])\n",
    "classified_claims_df[\"category_group\"] = np.where(classified_claims_df.category.isin([\"4_solutions_wont_work\", \"6_scientists_are_biased\", \"7_need_fossil_fuel\"]), \"Inaction\", classified_claims_df[\"category_group\"])\n",
    "classified_claims_df.category_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_claims_df[[\"category\", \"category_group\", \"quote\", \"context\", \"text\"]].to_csv(\"../../data/processed/claim_detections_classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "classified_df = pd.read_csv(\"../../data/processed/claim_detections_classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_y/jjyv0bm5597_x15dvpxnsmrc0000gn/T/ipykernel_42566/2328326546.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stratified_sample = classified_df.groupby('category_group').apply(\n",
      "/var/folders/_y/jjyv0bm5597_x15dvpxnsmrc0000gn/T/ipykernel_42566/2328326546.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stratified_sample_no_0 = classified_df[classified_df.category != \"0_accepted\"].groupby('category_group').apply(\n"
     ]
    }
   ],
   "source": [
    "stratified_sample = classified_df.groupby('category_group').apply(\n",
    "    lambda x: x.sample(n=100)\n",
    ").reset_index(drop=True).set_index(\"id\")\n",
    "\n",
    "stratified_sample_no_0 = classified_df[classified_df.category != \"0_accepted\"].groupby('category_group').apply(\n",
    "    lambda x: x.sample(n=100)\n",
    ").reset_index(drop=True).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_claims_df = stratified_sample.sample(frac=1)\n",
    "sample_claims_df[[\"category\", \"category_group\", \"quote\", \"context\", \"text\"]].to_csv(\"../../data/processed/claim_detections_classified_sample.csv\")\n",
    "\n",
    "sample_claims_df_no_0 = stratified_sample_no_0.sample(frac=1)\n",
    "sample_claims_df_no_0[[\"category\", \"category_group\", \"quote\", \"context\", \"text\"]].to_csv(\"../../data/processed/claim_detections_classified_sample_no_0.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
