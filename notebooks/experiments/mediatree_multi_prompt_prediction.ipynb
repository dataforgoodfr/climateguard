{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39131, 11)\n",
      "(15082, 11)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../../data/raw/4_channels_predictions_09_2023_09_2024.parquet\")\n",
    "print(df.shape)\n",
    "df.start = pd.to_datetime(df.start)\n",
    "cutoff = df.start.max() - pd.Timedelta(days=21)\n",
    "# df = df[df.start >= cutoff]\n",
    "df = df.loc[(df.start >= pd.to_datetime(\"2023-12-01\")) & (df.start <= pd.to_datetime(\"2024-06-01\"))]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15082.000000\n",
       "mean      2161.461477\n",
       "std        379.606272\n",
       "min        213.000000\n",
       "25%       1978.000000\n",
       "50%       2231.000000\n",
       "75%       2424.000000\n",
       "max       3116.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    15082.000000\n",
       "mean       482.950007\n",
       "std         85.832160\n",
       "min         53.000000\n",
       "25%        440.000000\n",
       "50%        498.000000\n",
       "75%        542.000000\n",
       "max        732.000000\n",
       "Name: num_tokens, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "channel_is_radio\n",
       "False    8723\n",
       "True     6359\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "channel_program_type\n",
       "Information - Magazine    7428\n",
       "Information en continu    6379\n",
       "Information - Journal     1275\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.text.str.len().describe())\n",
    "display(df.num_tokens.describe())\n",
    "\n",
    "display(df.channel_is_radio.value_counts())\n",
    "display(df.channel_program_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "from litellm import acompletion, completion_cost\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Callable, Awaitable, Union\n",
    "from functools import wraps\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "\n",
    "class MediatreePrediction(BaseModel):\n",
    "    cards_label_pred: str\n",
    "    prompt_tokens: int\n",
    "    completion_tokens: int\n",
    "    total_tokens: int\n",
    "    cost: float\n",
    "    claim_pred: str | None = None\n",
    "\n",
    "\n",
    "class MediatreeClaimIdentifier(BaseModel):\n",
    "    context: str = Field(\n",
    "        description=\"la phrase/paragraphe qui contient le contexte general\"\n",
    "    )\n",
    "    quote: str = Field(description=\"Citation exacte du texte contenant l'affirmation\")\n",
    "\n",
    "\n",
    "class MediatreeClaimIdentifierResponse(BaseModel):\n",
    "    claims: Union[list[MediatreeClaimIdentifier], None]\n",
    "    prompt_tokens: Union[int, None]\n",
    "    completion_tokens: Union[int, None]\n",
    "    total_tokens: Union[int, None]\n",
    "    cost: Union[float, None]\n",
    "\n",
    "\n",
    "async def report_experiment_results(\n",
    "    df: pd.DataFrame, predict_experiment: Callable[[str], Awaitable[None]]\n",
    ") -> None:\n",
    "    # Copy df to avoid modifications\n",
    "    df = df.copy()\n",
    "\n",
    "    # Run the experiment\n",
    "    mediatree_predictions: list[MediatreeClaimIdentifierResponse] = await tqdm.gather(\n",
    "        *[predict_experiment(text) for text in df[\"text\"]]\n",
    "    )\n",
    "    # Create lists to store individual claims and their metadata\n",
    "    rows = []\n",
    "\n",
    "    for idx, pred in zip(df.index, mediatree_predictions):\n",
    "        if pred is not None and pred.claims is not None:\n",
    "            for claim in pred.claims:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"id\": idx,\n",
    "                        \"context\": claim.context,\n",
    "                        \"quote\": claim.quote,\n",
    "                        \"prompt_tokens\": pred.prompt_tokens,\n",
    "                        \"completion_tokens\": pred.completion_tokens,\n",
    "                        \"total_tokens\": pred.total_tokens,\n",
    "                        \"cost\": pred.cost,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    # Create DataFrame with one claim per row\n",
    "    mediatree_predictions_df = pd.DataFrame(rows)\n",
    "\n",
    "    if not mediatree_predictions_df.empty:\n",
    "        # Set id as index if there are any claims\n",
    "        mediatree_predictions_df = mediatree_predictions_df.set_index(\"id\")\n",
    "    # df = pd.concat([df, mediatree_predictions_df], axis=1)\n",
    "    df = df.merge(\n",
    "        mediatree_predictions_df, left_index=True, right_index=True, how=\"outer\"\n",
    "    )\n",
    "\n",
    "    # Show stats and performance\n",
    "    show_llm_usage(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def show_llm_usage(df: pd.DataFrame) -> None:\n",
    "    print(\"\\nLLM USAGE\\n=========\\n\")\n",
    "    print(\n",
    "        f\"Median token usage:\\n- Prompt: {int(df[\"prompt_tokens\"].median())}\\n\"\n",
    "        f\"- Completion: {int(df[\"completion_tokens\"].median())}\\n\"\n",
    "        f\"- Total: {int(df[\"total_tokens\"].median())}\"\n",
    "    )\n",
    "    print(f\"\\nTotal cost: ${df[\"cost\"].sum():.3f}\\n\")\n",
    "\n",
    "\n",
    "# Limit concurrent requests to avoid API rate limiting\n",
    "# (it depends on the model you use and your API tier)\n",
    "semaphore = asyncio.Semaphore(40)\n",
    "\n",
    "\n",
    "# Decorator that ensures `acompletion` uses the semaphore\n",
    "def with_semaphore(acquire_semaphore):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        async def wrapper(*args, **kwargs):\n",
    "            async with acquire_semaphore:\n",
    "                return await func(*args, **kwargs)\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "acompletion = with_semaphore(semaphore)(acompletion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15082/15082 [09:09<00:00, 27.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM USAGE\n",
      "=========\n",
      "\n",
      "Median token usage:\n",
      "- Prompt: 999\n",
      "- Completion: 180\n",
      "- Total: 1178\n",
      "\n",
      "Total cost: $1.443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "async def extract_claims(text: str) -> MediatreeClaimIdentifierResponse:\n",
    "    system_prompt = \"\"\"\n",
    "Tu es un assistant spécialisé dans l'analyse de désinformation environnementale.\n",
    "\n",
    "TÂCHE:\n",
    "Analyse l'extrait de transcription TV/Radio fourni et identifie les affirmations (claims) qui nécessitent une vérification factuelle sur les thèmes suivants:\n",
    "- Changement climatique\n",
    "- Transition écologique\n",
    "- Énergie\n",
    "- Biodiversité\n",
    "- Pollution\n",
    "- Pesticides\n",
    "- Ressources naturelles (eau, minéraux, etc.)\n",
    "- Sort la quote seulement si t'est sure qu'elle continent de la désinformation environnementale/climatique.\n",
    "- Avec le quote il faute sortire la phrase/paragraphe qui contient le contexte general.\n",
    "- Pour exemple, le suivant texte:\n",
    "\"Merci monsieur Dupont, en fait je ne suis pas d'accord avec vous. Si on regard les dèrnieres jours, en France il fait plus froid que d'abitude ! Il y a pas de signes du rechauffement climatique !\"\n",
    "\n",
    "La quote est: \"Il y a pas de signes du rechauffement climatique !\"\n",
    "Et le context est: \"Si on regard les dèrnieres jours, en France il fait plus froid que d'abitude ! Il y a pas de signes du rechauffement climatique !\"\n",
    "\n",
    "FORMAT DE RÉPONSE:\n",
    "Tu dois OBLIGATOIREMENT répondre au format JSON suivant:\n",
    "{\n",
    "    \"claims\": [\n",
    "        {\n",
    "            \"context\": \"Un seul paragraphe résumant le contexte essentiel pour comprendre l'affirmation\",\n",
    "            \"quote\": \"Si on regard les dèrnieres jours, en France il fait plus froid que d'abitude ! Il y a pas de signes du rechauffement climatique !\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "RÈGLES IMPORTANTES:\n",
    "1. Inclure UNIQUEMENT les affirmations vérifiables sur les thèmes environnementaux contenant de la désinformation environnementale/climatique\n",
    "2. Chaque claim doit être unique\n",
    "3. Le format JSON doit être strictement respecté\n",
    "4. Si aucune affirmation à vérifier n'est trouvée, renvoyer les claims comme un json vide {\"claims\": []}\n",
    "5. Maximum 3 claims par analyse\n",
    "6. La quote doit être exactement la meme que dans le texte, et concener que la phrase incriminée.\n",
    "7. Le context doit être une phrase/paragraphe extrait et pas re-elaboré contenant la quote et plus de contexte.\n",
    "\n",
    "Analyse maintenant le texte suivant:\n",
    "\n",
    "\"\"\"\n",
    "    response = await acompletion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": text.strip()},\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0.01,\n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "    claim_identifier = response.choices[0].message.content\n",
    "    claims = (\n",
    "        [\n",
    "            MediatreeClaimIdentifier(**claim)\n",
    "            for claim in json.loads(claim_identifier)[\"claims\"]\n",
    "        ]\n",
    "        if json.loads(claim_identifier)[\"claims\"] != []\n",
    "        else None\n",
    "    )\n",
    "    return (\n",
    "        MediatreeClaimIdentifierResponse(\n",
    "            claims=claims,\n",
    "            prompt_tokens=response.usage.prompt_tokens,\n",
    "            completion_tokens=response.usage.completion_tokens,\n",
    "            total_tokens=response.usage.total_tokens,\n",
    "            cost=completion_cost(response),\n",
    "        )\n",
    "        if claims is not None\n",
    "        else None\n",
    "    )\n",
    "\n",
    "\n",
    "claim_detections = await report_experiment_results(df, extract_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16931 entries, 00057a237e27df45620beb329d9203ddba9749a67b3b94e90b85800e8d93c620 to fffc87c2d670e5368f1a5e0f43a430c4fdf99bf5042f1c9c3ea7ec9b08f8490e\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   start                 16931 non-null  datetime64[ns]\n",
      " 1   text                  16931 non-null  object        \n",
      " 2   channel_name          16931 non-null  object        \n",
      " 3   channel_is_radio      16931 non-null  bool          \n",
      " 4   channel_program_type  16931 non-null  object        \n",
      " 5   channel_program       16931 non-null  object        \n",
      " 6   themes                16931 non-null  object        \n",
      " 7   keywords              16931 non-null  object        \n",
      " 8   num_keywords          16931 non-null  int64         \n",
      " 9   num_tokens            16931 non-null  int64         \n",
      " 10  claims                16931 non-null  object        \n",
      " 11  context               5474 non-null   object        \n",
      " 12  quote                 5474 non-null   object        \n",
      " 13  prompt_tokens         5474 non-null   float64       \n",
      " 14  completion_tokens     5474 non-null   float64       \n",
      " 15  total_tokens          5474 non-null   float64       \n",
      " 16  cost                  5474 non-null   float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(4), int64(2), object(9)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "claim_detections.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_detections = claim_detections.dropna(subset=[\"context\", \"quote\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5474, 17)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim_detections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>quote</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000c11641b9a40d0bc7ea1e0be6437d1a69cb81043e67ac480e13c4986a294de</th>\n",
       "      <td>Un consensus qui arrivent en poils tard mais q...</td>\n",
       "      <td>un mix cent pourcent renouvelables il est poss...</td>\n",
       "      <td>cop vingt-huit s'engage à faire une transition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000c11641b9a40d0bc7ea1e0be6437d1a69cb81043e67ac480e13c4986a294de</th>\n",
       "      <td>autre engagement de cette cop vingt-huit tripl...</td>\n",
       "      <td>tripler les investissements dans ai les renouv...</td>\n",
       "      <td>cop vingt-huit s'engage à faire une transition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000cd7d6be597f6a569a45803f2648b8d096c4c7153a7e98ea63f0e827474f8a</th>\n",
       "      <td>mais même dans les endroits où ils sont bons i...</td>\n",
       "      <td>on va avoir des pluies de plus en plus diluvie...</td>\n",
       "      <td>un charles guyard arrivent au pire moment comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6ca7d1e8a22efed7bf0</th>\n",
       "      <td>est ce qu'entre écologie et agriculture il fau...</td>\n",
       "      <td>l'agriculture et je le cite une catastrophe hu...</td>\n",
       "      <td>capitalisme et le libre marché des normes envi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0057473cb2913c896ca5683b0c3a0d067cfc038d11afc381984404aca985ee77</th>\n",
       "      <td>elle annonce moins quatre-vingt-dix pour cent ...</td>\n",
       "      <td>moins quatre-vingt-dix pour cent de gaz à effe...</td>\n",
       "      <td>disent des annonces tu vas devoir vous le disa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff493499bb701e7c61da520140feea26b73a21c31a661d9883e94cfae39f0f25</th>\n",
       "      <td>Il faut qu'on continue de produire une aliment...</td>\n",
       "      <td>il faut qu'on continue de produire une aliment...</td>\n",
       "      <td>nourrir nos concitoyens nous pénaliser qu'aura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff493499bb701e7c61da520140feea26b73a21c31a661d9883e94cfae39f0f25</th>\n",
       "      <td>Aujourd'hui on a toujours voulu une agricultur...</td>\n",
       "      <td>une agriculture plus verte plus vertueuse pour...</td>\n",
       "      <td>nourrir nos concitoyens nous pénaliser qu'aura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff680102ed08ce32376fb5f635f846b44aecb52d27d074634c219255a06fd326</th>\n",
       "      <td>faut leur alléger les normes par exemple ce qu...</td>\n",
       "      <td>il faut leur alléger les normes par exemple ce...</td>\n",
       "      <td>faut leur alléger les normes par exemple ce qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff898a4273dbb51f28b4d7b18255104efa23e592064aaa6cfce653989aa4039d</th>\n",
       "      <td>les activistes accusent l'usine de polluer la ...</td>\n",
       "      <td>polluer la nappe phréatique et de consommer de...</td>\n",
       "      <td>américain thomas hermans c'est une action qui ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffb44918e05c51a7483508c0b710d077fdf10d422092460eded69936703f43f5</th>\n",
       "      <td>l'actualité c'est aussi la galère des lycéens ...</td>\n",
       "      <td>les catastrophes climatiques facture pour vert...</td>\n",
       "      <td>voilà retrouvez nos solutions simples et facil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5474 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              context  \\\n",
       "id                                                                                                      \n",
       "000c11641b9a40d0bc7ea1e0be6437d1a69cb81043e67ac...  Un consensus qui arrivent en poils tard mais q...   \n",
       "000c11641b9a40d0bc7ea1e0be6437d1a69cb81043e67ac...  autre engagement de cette cop vingt-huit tripl...   \n",
       "000cd7d6be597f6a569a45803f2648b8d096c4c7153a7e9...  mais même dans les endroits où ils sont bons i...   \n",
       "004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6c...  est ce qu'entre écologie et agriculture il fau...   \n",
       "0057473cb2913c896ca5683b0c3a0d067cfc038d11afc38...  elle annonce moins quatre-vingt-dix pour cent ...   \n",
       "...                                                                                               ...   \n",
       "ff493499bb701e7c61da520140feea26b73a21c31a661d9...  Il faut qu'on continue de produire une aliment...   \n",
       "ff493499bb701e7c61da520140feea26b73a21c31a661d9...  Aujourd'hui on a toujours voulu une agricultur...   \n",
       "ff680102ed08ce32376fb5f635f846b44aecb52d27d0746...  faut leur alléger les normes par exemple ce qu...   \n",
       "ff898a4273dbb51f28b4d7b18255104efa23e592064aaa6...  les activistes accusent l'usine de polluer la ...   \n",
       "ffb44918e05c51a7483508c0b710d077fdf10d422092460...  l'actualité c'est aussi la galère des lycéens ...   \n",
       "\n",
       "                                                                                                quote  \\\n",
       "id                                                                                                      \n",
       "000c11641b9a40d0bc7ea1e0be6437d1a69cb81043e67ac...  un mix cent pourcent renouvelables il est poss...   \n",
       "000c11641b9a40d0bc7ea1e0be6437d1a69cb81043e67ac...  tripler les investissements dans ai les renouv...   \n",
       "000cd7d6be597f6a569a45803f2648b8d096c4c7153a7e9...  on va avoir des pluies de plus en plus diluvie...   \n",
       "004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6c...  l'agriculture et je le cite une catastrophe hu...   \n",
       "0057473cb2913c896ca5683b0c3a0d067cfc038d11afc38...  moins quatre-vingt-dix pour cent de gaz à effe...   \n",
       "...                                                                                               ...   \n",
       "ff493499bb701e7c61da520140feea26b73a21c31a661d9...  il faut qu'on continue de produire une aliment...   \n",
       "ff493499bb701e7c61da520140feea26b73a21c31a661d9...  une agriculture plus verte plus vertueuse pour...   \n",
       "ff680102ed08ce32376fb5f635f846b44aecb52d27d0746...  il faut leur alléger les normes par exemple ce...   \n",
       "ff898a4273dbb51f28b4d7b18255104efa23e592064aaa6...  polluer la nappe phréatique et de consommer de...   \n",
       "ffb44918e05c51a7483508c0b710d077fdf10d422092460...  les catastrophes climatiques facture pour vert...   \n",
       "\n",
       "                                                                                                 text  \n",
       "id                                                                                                     \n",
       "000c11641b9a40d0bc7ea1e0be6437d1a69cb81043e67ac...  cop vingt-huit s'engage à faire une transition...  \n",
       "000c11641b9a40d0bc7ea1e0be6437d1a69cb81043e67ac...  cop vingt-huit s'engage à faire une transition...  \n",
       "000cd7d6be597f6a569a45803f2648b8d096c4c7153a7e9...  un charles guyard arrivent au pire moment comm...  \n",
       "004d1651ab85ba561a2a59e16bd67eb052acf4db8447f6c...  capitalisme et le libre marché des normes envi...  \n",
       "0057473cb2913c896ca5683b0c3a0d067cfc038d11afc38...  disent des annonces tu vas devoir vous le disa...  \n",
       "...                                                                                               ...  \n",
       "ff493499bb701e7c61da520140feea26b73a21c31a661d9...  nourrir nos concitoyens nous pénaliser qu'aura...  \n",
       "ff493499bb701e7c61da520140feea26b73a21c31a661d9...  nourrir nos concitoyens nous pénaliser qu'aura...  \n",
       "ff680102ed08ce32376fb5f635f846b44aecb52d27d0746...  faut leur alléger les normes par exemple ce qu...  \n",
       "ff898a4273dbb51f28b4d7b18255104efa23e592064aaa6...  américain thomas hermans c'est une action qui ...  \n",
       "ffb44918e05c51a7483508c0b710d077fdf10d422092460...  voilà retrouvez nos solutions simples et facil...  \n",
       "\n",
       "[5474 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim_detections[[\"context\", \"quote\", \"text\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_detections[[\"context\", \"quote\", \"text\"]].to_csv(\"../../data/processed/claim_detections_video_extractions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "914"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "INSTRUCTION_PROMPT = \"\"\"You are an expert in disinformation on environmental and climate subjects, expert in climate science and know everything about the GIEC. I am going to give you series of claims coming from quotes on medias. Among these, some will contain climate disinformation. Your task is to find disinformation claim if they exist, and classify them following the pre-defined categories.\n",
    "\n",
    "You must respond with a JSON object containing one field:\n",
    "- \"category\": the classification label\n",
    "\n",
    "<categories>\n",
    "- \"0_accepted\": No relevant environmental disinformation claim detected.\n",
    "- \"1_not_happening\": Global warming is not happing. Climate change is NOT leading to melting ice (such as glaciers, sea ice, and permafrost), increased extreme weather, or rising sea levels. Cold weather also shows that climate change is not happening.\n",
    "- \"2_not_human\": Greenhouse gases from humans are not the causing climate change.\n",
    "- \"3_not_bad\": The impacts of climate change will not be bad and might even be beneficial.\n",
    "- \"4_solutions_wont_work\": Climate solutions are harmful or unnecessary.\n",
    "- \"5_science_is_unreliable\": Climate science is uncertain, unsound, unreliable, or biased.\n",
    "- \"6_scientists_are_biased\": Climate scientists and proponents of climate action are alarmist, biased, wrong, hypocritical, corrupt, and/or politically motivated.\n",
    "- \"7_need_fossil_fuel\": We need fossil fuels for economic growth, prosperity, and to maintain our standard of living.\n",
    "</categories>\n",
    "\"\"\"\n",
    "\n",
    "EXAMPLES_PROMPT = \"\"\"\n",
    "<examples>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "A warmer planet will actually be good for agriculture—more CO2 means bigger crops and longer growing seasons!\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "more CO2 means bigger crops and longer growing seasons!\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"3_not_bad\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "The data is clear: the Earth is warming due to human activities, and immediate action is required to mitigate its effects.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "the Earth is warming due to human activities, and immediate action is required to mitigate its effects.\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"0_accepted\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "Global warming is just a myth pushed by elites—if the planet were really heating up, why did we just have the coldest winter in decades?\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "Global warming is just a myth pushed by elites\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"1_not_happening\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "These so-called climate experts are just chasing grant money, hyping up fear to keep their funding flowing.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "climate experts are just chasing grant money\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"6_scientists_are_biased\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "Climate models have been wrong so many times; why should we trust them now? They're just guesses based on incomplete data.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "Climate models have been wrong so many times\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"5_science_is_unreliable\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "Climate has always changed naturally throughout history; blaming humans for it is absurd and ignores natural cycles like solar activity.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "Climate has always changed naturally throughout history\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"2_not_human\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "Switching to renewable energy will cripple our economy without making any real difference to the planet's temperature.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "Switching to renewable energy will cripple our economy\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"4_solutions_wont_work\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "<extract>\n",
    "Without fossil fuels, our society would collapse—we can't power modern civilization on wind turbines and solar panels alone.\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "Without fossil fuels, our society would collapse\n",
    "</highlighted_quote>\n",
    "<response>\n",
    "{\n",
    "    \"category\": \"7_need_fossil_fuel\"\n",
    "}\n",
    "</response>\n",
    "</example>\n",
    "\n",
    "</examples>\"\"\"\n",
    "\n",
    "FEW_SHOT_PROMPT = INSTRUCTION_PROMPT + EXAMPLES_PROMPT\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "len(encoding.encode(FEW_SHOT_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "Extract to analyze:\n",
    "<extract>\n",
    "{context}\n",
    "</extract>\n",
    "<highlighted_quote>\n",
    "{quote}\n",
    "</highlighted_quote>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MediatreeClaimCardsClassification(BaseModel):\n",
    "    category: str = Field(\n",
    "        description=\"Label of the disinformation type\"\n",
    "    )\n",
    "\n",
    "\n",
    "async def classify(\n",
    "    system_prompt: str, user_prompt: str\n",
    ") -> MediatreeClaimCardsClassification:\n",
    "    response = await acompletion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.01,\n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "    claim_validity = response.choices[0].message.content\n",
    "    return MediatreeClaimCardsClassification(**json.loads(claim_validity))\n",
    "\n",
    "\n",
    "async def classify_claims(claims_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    claim_classifications: list[MediatreeClaimCardsClassification] = await tqdm.gather(\n",
    "        *[\n",
    "            classify(\n",
    "                FEW_SHOT_PROMPT,\n",
    "                USER_PROMPT_TEMPLATE.format(\n",
    "                    context=claim.context, quote=claim.quote\n",
    "                ),\n",
    "            )\n",
    "            for claim in claims_df.itertuples()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    claim_classifications_df = pd.DataFrame(\n",
    "        [classification.model_dump(exclude_none=True) for classification in claim_classifications],\n",
    "        index=claims_df.index,\n",
    "    )\n",
    "\n",
    "    claim_classifications_df = pd.concat([claims_df, claim_classifications_df], axis=1)\n",
    "\n",
    "    return claim_classifications_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5474/5474 [02:45<00:00, 33.01it/s]\n"
     ]
    }
   ],
   "source": [
    "classified_claims_df = await classify_claims(claim_detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "0_accepted                 4565\n",
       "4_solutions_wont_work       518\n",
       "1_not_happening             147\n",
       "6_scientists_are_biased      76\n",
       "5_science_is_unreliable      64\n",
       "2_not_human                  40\n",
       "3_not_bad                    35\n",
       "7_need_fossil_fuel           29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_claims_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_claims_df[[\"category\", \"quote\", \"context\", \"text\"]].to_csv(\"../../data/processed/claim_detections_classified.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "classified_df = pd.read_csv(\"../../data/processed/claim_detections_classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_y/jjyv0bm5597_x15dvpxnsmrc0000gn/T/ipykernel_17590/3081043153.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stratified_sample = classified_df.groupby('category').apply(\n",
      "/var/folders/_y/jjyv0bm5597_x15dvpxnsmrc0000gn/T/ipykernel_17590/3081043153.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stratified_sample_no_0 = classified_df[classified_df.category != \"0_accepted\"].groupby('category').apply(\n"
     ]
    }
   ],
   "source": [
    "stratified_sample = classified_df.groupby('category').apply(\n",
    "    lambda x: x.sample(n=20)\n",
    ").reset_index(drop=True).set_index(\"id\")\n",
    "\n",
    "stratified_sample_no_0 = classified_df[classified_df.category != \"0_accepted\"].groupby('category').apply(\n",
    "    lambda x: x.sample(n=20)\n",
    ").reset_index(drop=True).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_claims_df = stratified_sample.sample(frac=1)\n",
    "sample_claims_df[[\"category\", \"quote\", \"context\", \"text\"]].to_csv(\"../../data/processed/claim_detections_classified_sample.csv\")\n",
    "\n",
    "sample_claims_df_no_0 = stratified_sample_no_0.sample(frac=1)\n",
    "sample_claims_df_no_0[[\"category\", \"quote\", \"context\", \"text\"]].to_csv(\"../../data/processed/claim_detections_classified_sample_no_0.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
