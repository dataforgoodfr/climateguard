{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "from functools import wraps\n",
    "from typing import Literal\n",
    "import litellm\n",
    "import pandas as pd\n",
    "from litellm import acompletion\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm.asyncio import tqdm\n",
    "from pydantic import BaseModel\n",
    "from litellm import completion_cost\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from climateguard.evaluation import (\n",
    "    plot_cards_confusion_matrix,\n",
    "    plot_binary_confusion_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the labeled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>quote_true</th>\n",
       "      <th>is_contrarian_true</th>\n",
       "      <th>is_contrarian_pred</th>\n",
       "      <th>cards_true</th>\n",
       "      <th>cards_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bbb629698dfd9319801</th>\n",
       "      <td>Jusqu'au trente septembre, détaille Sofia au q...</td>\n",
       "      <td>Il y a beaucoup de soldats poneys menteurs à t...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>5_science_uncertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0fb8db32982baea27fa4a92220e76331e703d61852c0e8d95550ef6853ffd842</th>\n",
       "      <td>On tente d'échapper à une tempête de pluie d'a...</td>\n",
       "      <td>tempête de pluie d'acide mortelle selon l'inrs...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>1_its_not_happening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a9b18aa5c7581c9e02</th>\n",
       "      <td>Les Français n'arrivent pas à se loger, c'est ...</td>\n",
       "      <td>Ça va de l'interdiction des avions d'affaires ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6_proponents_biased</td>\n",
       "      <td>3_impacts_not_bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b58b532791a33aba423</th>\n",
       "      <td>Le réchauffement climatique a été collecté à G...</td>\n",
       "      <td>on ne peut pas faire le lien directement avec ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2_humans_not_the_cause</td>\n",
       "      <td>2_humans_not_the_cause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>af3a15d298ff642982bcd6c79c21b56623649a140ce3558316dea54ea7ce0f3e</th>\n",
       "      <td>Vous avez ce livre qui est une bande dessinée,...</td>\n",
       "      <td>la crise écologique va rendre la terre inhospi...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>1_its_not_happening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72e86031b0690309ec7</th>\n",
       "      <td>Il l'affirme, la piste criminelle est toujours...</td>\n",
       "      <td>les utilisés PFAS dans utilisés la dans fabric...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>5_science_uncertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58feacdc4a4d31023a87bce158ee902d37076d9f5562f3fe41f768ba815b7b6a</th>\n",
       "      <td>Aujourd'hui, ce fameux pacte d'immigration qui...</td>\n",
       "      <td>ce tsunami de normes de contraintes de taxe qu...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4_solutions_harmful_unnecessary</td>\n",
       "      <td>4_solutions_harmful_unnecessary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34308b71c22c78217ec</th>\n",
       "      <td>Avec l'aide de nos fournisseurs, si il s'avère...</td>\n",
       "      <td>l'entreprise n'a pas voulu nous dire combien d...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>4_solutions_harmful_unnecessary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9ec1c82a2ebfb251527</th>\n",
       "      <td>En France, plusieurs millions de maisons sont ...</td>\n",
       "      <td>le dérèglement climatique phénomène naturel.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>2_humans_not_the_cause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cdfed233896d49971897df448465dd43b79ae871b33adb5a3a5d464755e8a7cb</th>\n",
       "      <td>Les insectes, non, on pense que c'est la chale...</td>\n",
       "      <td>le progrès sur le réchauffement climatique la ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>3_impacts_not_bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text  \\\n",
       "id                                                                                                      \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...  Jusqu'au trente septembre, détaille Sofia au q...   \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...  On tente d'échapper à une tempête de pluie d'a...   \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...  Les Français n'arrivent pas à se loger, c'est ...   \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...  Le réchauffement climatique a été collecté à G...   \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...  Vous avez ce livre qui est une bande dessinée,...   \n",
       "...                                                                                               ...   \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...  Il l'affirme, la piste criminelle est toujours...   \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...  Aujourd'hui, ce fameux pacte d'immigration qui...   \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...  Avec l'aide de nos fournisseurs, si il s'avère...   \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...  En France, plusieurs millions de maisons sont ...   \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...  Les insectes, non, on pense que c'est la chale...   \n",
       "\n",
       "                                                                                           quote_true  \\\n",
       "id                                                                                                      \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...  Il y a beaucoup de soldats poneys menteurs à t...   \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...  tempête de pluie d'acide mortelle selon l'inrs...   \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...  Ça va de l'interdiction des avions d'affaires ...   \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...  on ne peut pas faire le lien directement avec ...   \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...  la crise écologique va rendre la terre inhospi...   \n",
       "...                                                                                               ...   \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...  les utilisés PFAS dans utilisés la dans fabric...   \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...  ce tsunami de normes de contraintes de taxe qu...   \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...  l'entreprise n'a pas voulu nous dire combien d...   \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...       le dérèglement climatique phénomène naturel.   \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...  le progrès sur le réchauffement climatique la ...   \n",
       "\n",
       "                                                    is_contrarian_true  \\\n",
       "id                                                                       \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...               False   \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...               False   \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...                True   \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...                True   \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...               False   \n",
       "...                                                                ...   \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...               False   \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...                True   \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...               False   \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...               False   \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...               False   \n",
       "\n",
       "                                                    is_contrarian_pred  \\\n",
       "id                                                                       \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...                True   \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...                True   \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...                True   \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...                True   \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...                True   \n",
       "...                                                                ...   \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...                True   \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...                True   \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...                True   \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...                True   \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...                True   \n",
       "\n",
       "                                                                         cards_true  \\\n",
       "id                                                                                    \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...                       0_accepted   \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...                       0_accepted   \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...              6_proponents_biased   \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...           2_humans_not_the_cause   \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...                       0_accepted   \n",
       "...                                                                             ...   \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...                       0_accepted   \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...  4_solutions_harmful_unnecessary   \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...                       0_accepted   \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...                       0_accepted   \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...                       0_accepted   \n",
       "\n",
       "                                                                         cards_pred  \n",
       "id                                                                                   \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...              5_science_uncertain  \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...              1_its_not_happening  \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...                3_impacts_not_bad  \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...           2_humans_not_the_cause  \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...              1_its_not_happening  \n",
       "...                                                                             ...  \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...              5_science_uncertain  \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...  4_solutions_harmful_unnecessary  \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...  4_solutions_harmful_unnecessary  \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...           2_humans_not_the_cause  \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...                3_impacts_not_bad  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from the human labeled Excel file\n",
    "df = pd.read_csv(\n",
    "    \"../../data/raw/4_channels_review_09_2023_09_2024.xlsx - Claims review.csv\",\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "# Filter the records that have been labeled\n",
    "df = df[\n",
    "    # Only keep the records with a ground truth label\n",
    "    ~df[\"cards_ground_truth\"].isna()\n",
    "    # Only keep the records with a correctly identified quote since the current labelling UX doesn't allow to identify the correct quotes\n",
    "    & (df[\"quote_is_correct\"] == \"TRUE\")\n",
    "    # Some \"commentaire_quote\" mention that the identified quote is either incorrect or partially correct, we ignore these records\n",
    "    & (df[\"commentaire_quote\"].isna())\n",
    "]\n",
    "\n",
    "# Only keep the relevant columns\n",
    "df[\"is_contrarian_true\"] = df[\"cards_ground_truth\"] != \"0_accepted\"\n",
    "df[\"is_contrarian_pred\"] = df[\"cards\"] != \"0_accepted\"\n",
    "df = df[\n",
    "    [\n",
    "        \"text\",\n",
    "        \"quote\",\n",
    "        \"is_contrarian_true\",\n",
    "        \"is_contrarian_pred\",\n",
    "        \"cards_ground_truth\",\n",
    "        \"cards\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"cards_ground_truth\": \"cards_true\",\n",
    "        \"cards\": \"cards_pred\",\n",
    "        \"quote\": \"quote_true\",\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "hoverinfo": "none",
         "showscale": false,
         "text": [
          [
           "0",
           "37<br>48.68%",
           "2<br>2.63%",
           "8<br>10.53%",
           "17<br>22.37%",
           "6<br>7.89%",
           "5<br>6.58%",
           "1<br>1.32%"
          ],
          [
           "0",
           "13<br>81.25%",
           "3<br>18.75%",
           "0",
           "0",
           "0",
           "0",
           "0"
          ],
          [
           "0",
           "2<br>15.38%",
           "11<br>84.62%",
           "0",
           "0",
           "0",
           "0",
           "0"
          ],
          [
           "0",
           "2<br>18.18%",
           "1<br>9.09%",
           "8<br>72.73%",
           "0",
           "0",
           "0",
           "0"
          ],
          [
           "0",
           "7<br>14.29%",
           "3<br>6.12%",
           "7<br>14.29%",
           "28<br>57.14%",
           "1<br>2.04%",
           "1<br>2.04%",
           "2<br>4.08%"
          ],
          [
           "0",
           "1<br>10%",
           "0",
           "0",
           "0",
           "9<br>90%",
           "0",
           "0"
          ],
          [
           "0",
           "1<br>4.76%",
           "0",
           "1<br>4.76%",
           "4<br>19.05%",
           "2<br>9.52%",
           "13<br>61.90%",
           "0"
          ],
          [
           "0",
           "0",
           "0",
           "0",
           "0",
           "0",
           "0",
           "4<br>100%"
          ]
         ],
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "0_accepted",
          "1_its_not_happening",
          "2_humans_not_the_cause",
          "3_impacts_not_bad",
          "4_solutions_harmful_unnecessary",
          "5_science_uncertain",
          "6_proponents_biased",
          "7_fossil_fuels_needed"
         ],
         "y": [
          "0_accepted",
          "1_its_not_happening",
          "2_humans_not_the_cause",
          "3_impacts_not_bad",
          "4_solutions_harmful_unnecessary",
          "5_science_uncertain",
          "6_proponents_biased",
          "7_fossil_fuels_needed"
         ],
         "z": [
          [
           0,
           0.4868421052631579,
           0.02631578947368421,
           0.10526315789473684,
           0.2236842105263158,
           0.07894736842105263,
           0.06578947368421052,
           0.013157894736842105
          ],
          [
           0,
           0.8125,
           0.1875,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0.15384615384615385,
           0.8461538461538461,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0.18181818181818182,
           0.09090909090909091,
           0.7272727272727273,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0.14285714285714285,
           0.061224489795918366,
           0.14285714285714285,
           0.5714285714285714,
           0.02040816326530612,
           0.02040816326530612,
           0.04081632653061224
          ],
          [
           0,
           0.1,
           0,
           0,
           0,
           0.9,
           0,
           0
          ],
          [
           0,
           0.047619047619047616,
           0,
           0.047619047619047616,
           0.19047619047619047,
           0.09523809523809523,
           0.6190476190476191,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1
          ]
         ]
        }
       ],
       "layout": {
        "height": 600,
        "margin": {
         "b": 25,
         "r": 25,
         "t": 40
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Confusion Matrix",
         "x": 0.5,
         "xref": "paper",
         "y": 0.97
        },
        "width": 700,
        "xaxis": {
         "tickangle": -30,
         "title": {
          "text": "Predicted class"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "True class"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cards_confusion_matrix(\n",
    "    df[\"cards_true\"],\n",
    "    df[\"cards_pred\"],\n",
    "    [\n",
    "        \"0_accepted\",\n",
    "        \"1_its_not_happening\",\n",
    "        \"2_humans_not_the_cause\",\n",
    "        \"3_impacts_not_bad\",\n",
    "        \"4_solutions_harmful_unnecessary\",\n",
    "        \"5_science_uncertain\",\n",
    "        \"6_proponents_biased\",\n",
    "        \"7_fossil_fuels_needed\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00        76\n",
      "        True       0.62      1.00      0.77       124\n",
      "\n",
      "    accuracy                           0.62       200\n",
      "   macro avg       0.31      0.50      0.38       200\n",
      "weighted avg       0.38      0.62      0.47       200\n",
      "\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                     0_accepted       0.00      0.00      0.00        76\n",
      "            1_its_not_happening       0.21      0.81      0.33        16\n",
      "         2_humans_not_the_cause       0.55      0.85      0.67        13\n",
      "              3_impacts_not_bad       0.33      0.73      0.46        11\n",
      "4_solutions_harmful_unnecessary       0.57      0.57      0.57        49\n",
      "            5_science_uncertain       0.50      0.90      0.64        10\n",
      "            6_proponents_biased       0.68      0.62      0.65        21\n",
      "          7_fossil_fuels_needed       0.57      1.00      0.73         4\n",
      "\n",
      "                       accuracy                           0.43       200\n",
      "                      macro avg       0.43      0.68      0.51       200\n",
      "                   weighted avg       0.32      0.43      0.35       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        df[\"is_contrarian_true\"], df[\"is_contrarian_pred\"], zero_division=0\n",
    "    )\n",
    ")\n",
    "print(classification_report(df[\"cards_true\"], df[\"cards_pred\"], zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"is_contrarian_pred\", \"cards_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.iloc[:5].copy()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n",
      "Caught an exception in \"detect_claims\", retrying in 10 seconds...\n",
      "Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 101\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaims_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[detect_claims(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n",
      "File \u001b[0;32m~/Desktop/climateguard/.venv/lib/python3.12/site-packages/tqdm/asyncio.py:79\u001b[0m, in \u001b[0;36mtqdm_asyncio.gather\u001b[0;34m(cls, loop, timeout, total, *fs, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m i, \u001b[38;5;28;01mawait\u001b[39;00m f\n\u001b[1;32m     78\u001b[0m ifs \u001b[38;5;241m=\u001b[39m [wrap_awaitable(i, f) \u001b[38;5;28;01mfor\u001b[39;00m i, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fs)]\n\u001b[0;32m---> 79\u001b[0m res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mawait\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mas_completed(ifs, loop\u001b[38;5;241m=\u001b[39mloop, timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m     80\u001b[0m                                          total\u001b[38;5;241m=\u001b[39mtotal, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtqdm_kwargs)]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [i \u001b[38;5;28;01mfor\u001b[39;00m _, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(res)]\n",
      "File \u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py:627\u001b[0m, in \u001b[0;36mas_completed.<locals>._wait_for_one\u001b[0;34m()\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_for_one\u001b[39m():\n\u001b[0;32m--> 627\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m done\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;66;03m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTimeoutError\n",
      "File \u001b[0;32m/usr/lib/python3.12/asyncio/queues.py:158\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getters\u001b[38;5;241m.\u001b[39mappend(getter)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m getter\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     getter\u001b[38;5;241m.\u001b[39mcancel()  \u001b[38;5;66;03m# Just in case getter is not done yet.\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "# Limit concurrent requests to avoid API rate limiting\n",
    "# (it depends on the model you use and your API tier)\n",
    "semaphore = asyncio.Semaphore(100)\n",
    "\n",
    "\n",
    "class MediatreePrediction(BaseModel):\n",
    "    label_pred: str\n",
    "    prompt_tokens: int\n",
    "    completion_tokens: int\n",
    "    total_tokens: int\n",
    "    cost: float\n",
    "    claim_pred: str | None = None\n",
    "\n",
    "\n",
    "class Claim(BaseModel):\n",
    "    claim: str\n",
    "    context: str\n",
    "    analysis: str\n",
    "    disinformation_score: Literal[\"very low\", \"low\", \"medium\", \"high\"]\n",
    "    disinformation_category: str\n",
    "    pro_anti: Literal[\"pro-écologie\", \"anti-écologie\"]\n",
    "    speaker: Literal[\"consensus\", \"facts\", \"narrative\", \"other\"]\n",
    "    contradiction: str\n",
    "    quote: str\n",
    "\n",
    "\n",
    "class Claims(BaseModel):\n",
    "    claims: list[Claim]\n",
    "\n",
    "\n",
    "async def detect_claims(transcription):\n",
    "    prompt = f\"\"\"Tu es expert en désinformation sur les sujets environnementaux, expert en science climatique et sachant tout sur le GIEC. Je vais te donner un extrait d'une retranscription de 2 minutes d'un flux TV ou Radio. \n",
    "A partir de cet extrait liste moi tous les faits/opinions environnementaux (claim) uniques qu'il faudrait factchecker. Et pour chaque claim, donne une première analyse si c'est de la désinformation ou non, un score si c'est de la désinformation, ainsi qu'une catégorisation de cette allégation.\n",
    "Ne sélectionne que les claims sur les thématiques environnementales (changement climatique, transition écologique, énergie, biodiversité, pollution, pesticides, ressources (eau, minéraux, ..) et pas sur les thématiques sociales et/ou économiques\n",
    "Renvoie le résultat en json sans autre phrase d'introduction ou de conclusion avec à chaque fois les champs suivants : \n",
    "\n",
    "- \"claim\" - l'allégation à potentiellement vérifier\n",
    "- \"context\" - reformulation du contexte dans laquelle cette allégation a été prononcée (maximum 1 paragraphe)\n",
    "- \"analysis\" - première analyse du point de vue de l'expert sur le potentiel de désinformation de cette allégation en fonction du contexte\n",
    "- \"disinformation_score\" - le score de désinformation (voir plus bas)\n",
    "- \"disinformation_category\" - la catégorie de désinformation (voir plus bas)\n",
    "- \"pro_anti\" - si l'allégation est plutôt anti-écologie ou pro-écologie\n",
    "- \"speaker\" - nom et fonction de la personne qui a prononcé l'allégation si on a l'information (sinon \"N/A\")\n",
    "- \"contradiction\" - si l'allégation a été contestée dans un dialogue, résume la contradiction (sinon \"N/A\")\n",
    "- \"quote\" - la citation exacte qui correspond à l'allégation\n",
    "\n",
    "Pour les scores \"disinformation_score\"\n",
    "- \"very low\" = pas de problème, l'allégation n'est pas trompeuse ou à risque. pas besoin d'investiguer plus loin\n",
    "- \"low\" = allégation qui nécessiterait une vérification et une interrogation, mais sur un sujet peu important et significatif dans le contexte des enjeux écologiques (exemple : les tondeuses à gazon, \n",
    "- \"medium\" = allégation problématique sur un sujet écologique important (scientifique, impacts, élections, politique, transport, agriculture, énergie, alimentation, démocratie ...) , qui nécessiterait vraiment d'être vérifiée, déconstruite, débunkée et interrogée. En particulier pour les opinions fallacieuses\n",
    "- \"high\" = allégation grave, en particulier si elle nie le consensus scientifique\n",
    "\n",
    "Pour les catégories de désinformation \"disinformation_category\": \n",
    "- \"consensus\" = négation du consensus scientifique\n",
    "- \"facts\" = fait à vérifier, à préciser ou contextualiser\n",
    "- \"narrative\" = narratif fallacieux ou opinion qui sème le doute (par exemple : \"les écolos veulent nous enlever nos libertés\")\n",
    "- \"other\"\n",
    "\n",
    "<transcription>\n",
    "{transcription}\n",
    "</transcription>\"\"\"\n",
    "    async with semaphore:\n",
    "        # Retry if errors\n",
    "        while True:\n",
    "            try:\n",
    "                completion = await client.beta.chat.completions.parse(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    response_format=Claims,\n",
    "                )\n",
    "                break\n",
    "            except (\n",
    "                Exception\n",
    "                # litellm.exceptions.RateLimitError,\n",
    "                # litellm.exceptions.Timeout,\n",
    "                # litellm.exceptions.APIConnectionError,\n",
    "                # litellm.exceptions.InternalServerError,\n",
    "                # litellm.exceptions.ServiceUnavailableError,\n",
    "            ) as e:\n",
    "                print(\n",
    "                    'Caught an exception in \"detect_claims\", retrying in 10 seconds...'\n",
    "                )\n",
    "                print(e)\n",
    "                await asyncio.sleep(10)\n",
    "\n",
    "    claims_data = completion.choices[0].message.parsed\n",
    "    result = [\n",
    "        claim.model_dump()\n",
    "        for claim in claims_data.claims\n",
    "        if claim.pro_anti == \"anti-écologie\"\n",
    "    ]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "df[\"claims_pred\"] = await tqdm.gather(*[detect_claims(text) for text in df[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.16      0.26        76\n",
      "        True       0.65      0.97      0.78       124\n",
      "\n",
      "    accuracy                           0.66       200\n",
      "   macro avg       0.70      0.56      0.52       200\n",
      "weighted avg       0.69      0.66      0.58       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "hoverinfo": "none",
         "showscale": false,
         "text": [
          [
           "12<br>15.79%",
           "64<br>84.21%"
          ],
          [
           "4<br>3.23%",
           "120<br>96.77%"
          ]
         ],
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "0_accepted",
          "[1-5]_contrarian"
         ],
         "y": [
          "0_accepted",
          "[1-5]_contrarian"
         ],
         "z": [
          [
           0.15789473684210525,
           0.8421052631578947
          ],
          [
           0.03225806451612903,
           0.967741935483871
          ]
         ]
        }
       ],
       "layout": {
        "height": 600,
        "margin": {
         "b": 25,
         "r": 25,
         "t": 40
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Confusion Matrix",
         "x": 0.5,
         "xref": "paper",
         "y": 0.97
        },
        "width": 700,
        "xaxis": {
         "tickangle": -30,
         "title": {
          "text": "Predicted class"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "True class"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Is contrarian if we detected a claim\n",
    "df[\"is_contrarian_pred\"] = df[\"claims_pred\"].str.len() > 0\n",
    "print(classification_report(df[\"is_contrarian_true\"], df[\"is_contrarian_pred\"]))\n",
    "plot_binary_confusion_matrix(df[\"is_contrarian_true\"], df[\"is_contrarian_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.59      0.59        76\n",
      "        True       0.75      0.74      0.74       124\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"claims_pred_high\"] = df[\"claims_pred\"].apply(\n",
    "    lambda claims: [\n",
    "        claim for claim in claims if claim[\"disinformation_score\"] == \"high\"\n",
    "    ]\n",
    ")\n",
    "df[\"is_contrarian_pred\"] = df[\"claims_pred_high\"].str.len() > 0\n",
    "print(classification_report(df[\"is_contrarian_true\"], df[\"is_contrarian_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 26.26it/s] \n"
     ]
    }
   ],
   "source": [
    "# Actually I realized the descriptions of categories don't help with performance\n",
    "# It's a bit surprising... maybe the few-shot claim examples are very similar to the test claims?\n",
    "async def detect_claims(text: str) -> MediatreePrediction:\n",
    "    system_prompt = \"\"\"Tu es expert en désinformation sur les sujets environnementaux, expert en science climatique et sachant tout sur le GIEC. Je vais te donner un extrait d'une retranscription de 2 minutes d'un flux TV ou Radio. Certains extraits contiennent un passage climatosceptique qui mérite d'être factchecker. Ta tâche est de trouver ce passage climatosceptique (si il existe). Après avoir analyser l'extrait, isole le passage à factchecker.\n",
    "\n",
    "# Étapes\n",
    "\n",
    "1. Lire attentivement l'extrait fourni : Se concentrer sur les propos liés au climat, au réchauffement climatique ou aux phénomènes météorologiques extrêmes. Ignorer les discussions non pertinentes (économie, société, etc.).\n",
    "2. Détecter les éléments potentiellement climatosceptiques. Voilà quelques catégories de désinformation :\n",
    "   - Négation du changement climatique : Affirme que le réchauffement climatique n'existe pas et que les phénomènes associés, comme la fonte des glaces ou les événements climatiques extrêmes, ne se produisent pas.\n",
    "   - Rejet de la responsabilité humaine : Soutient que les gaz à effet de serre émis par les activités humaines ne sont pas la cause du changement climatique.\n",
    "   - Minimisation des impacts : Suggère que les effets du changement climatique ne seront pas graves et pourraient même avoir des avantages.\n",
    "   - Opposition aux solutions climatiques : Considère que les mesures pour lutter contre le changement climatique sont nuisibles ou inutiles.\n",
    "   - Critique de la science climatique : Remet en question la fiabilité, la validité et l’objectivité des sciences liées au climat.\n",
    "   - Attaques contre les défenseurs de l’action climatique : Accuse les scientifiques et les militants d’être alarmistes, biaisés, corrompus ou motivés politiquement.\n",
    "   - Promotion des énergies fossiles : Défend les combustibles fossiles comme essentiels pour la croissance économique, la prospérité et le maintien du niveau de vie.\n",
    "4. Extraire le passage climatosceptique. Si aucun passage climatosceptique n’est trouvé : Répondre avec une balise indiquant AUCUN.\n",
    "\n",
    "# Format de réponse\n",
    "\n",
    "Fournis le passage climatosceptique au dans des tags XML:\n",
    "\n",
    "```xml\n",
    "<passage climatosceptique>\n",
    "[...]\n",
    "</passage climatosceptique>\n",
    "```\n",
    "\n",
    "Débute ta réponse par \"<passage climatosceptique>\".\n",
    "\n",
    "# Exemples\n",
    "\n",
    "## Exemple sans désinformation\n",
    "\n",
    "<extrait>\n",
    "Les climats qui se multiplient, elles sont en poste, ont appelé à cette pause. Non, non seulement il ne faut pas une pause, le réchauffement climatique est en cours. Voilà, enfin, elle aurait bien besoin d'une pause. C'est Valéry, ça devient inquiétant. Écoutez, parler de la fin des voitures thermiques, c'est un impératif économique, puisqu'un plein d'une voiture électrique est beaucoup moins cher qu'un plein d'une voiture à essence. Au début, il faut le dire, le président Pascal va finir par Calais, je crois. Enfin bon, bref, quand il y a un débat sur l'écologie, normalement, les écolos sont plus forts, oui, forcément, sauf quand c'est Marie Toussaint. Or, moi, je connais la proposition du Shift, qui est celle de limiter les vols à Paris. Donc, par et personne, bien sûr, je suis obligé de faire une gratification instantanée. Ce n'est pas une proposition du Shift, je croyais banni. Donc, même dans leurs domaines de prédilection, ils n'arrivent pas. Bon, là, ça va être compliqué. Tout savoir, ça pousse. Cette chanson, c'est ce qui est maintenant, c'est les rouges et plus. Merci beaucoup, Dimitri Bernet, le zapping politique sur Europe 1, à retrouver sur europe1.fr. Sur les réseaux sociaux également, vous nous avez donné tout à l'heure le premier invité de Culture Médias, à partir de neuf heures et demie sur Europe 1, que David Ginola. C'est pour la série au micro. Alors, c'est très intéressant, c'est très marrant, cette série, trouver le nouveau commentateur. En fait, seize voix, mais du commentaire de Joe en août à travers plusieurs villes. Il y a eu déjà à Paris, il va y avoir plein d'autres étapes, Lille, Marseille, et David fait partie du comité de sélection. Et à partir de dix heures, c'est là que le scandale arrive. Inès Reg, vous savez, danse avec les stars, touche à tout, ça pour son nouveau spectacle, c'est avec Jean-Pierre Foucault.\n",
    "</extrait>\n",
    "<passage climatosceptique>\n",
    "AUCUN\n",
    "</passage climatosceptique>\n",
    "\n",
    "## Exemple avec désinformation\n",
    "\n",
    "<extrait>\n",
    "À ce trafic, hein, mais comme derrière, on n'a ni places de prison ni volonté des magistrats d'embastiller sur des durées longues et dissuasives, on a perdu sur tous les tableaux. Donc, on ne fait qu'augmenter la violence. En réalité, c'est cette politique consistant à taper sur les points de deal. Je ne suis pas contre, sauf que s'il n'y a pas de répression pénale derrière, eh bien, vous ne ferez qu'accroître la violence. Alors que la France est épinglée par l'Europe pour ses dispenses d'interdiction des néonicotinoïdes en 2021 et 2022, l'Office français de la biodiversité demande à ses inspecteurs de ne pas contrôler les arboriculteurs, pourtant grands consommateurs de pesticides, des produits essentiels à leur survie. Illustration en Seine-et-Marne de Florent Ferro et de Sarah. Les néonicotinoïdes ont été bannis de l'agriculture française en 2018. À cause de l'interdiction, cet agriculteur a dû couper tous ses cerisiers. Le champ de cerisiers, notre chambre cerisier, cerisier, mille sept cents arbres ont été arrachés. Finalement, la possibilité de maintenir une production dans la légalité représente un véritable danger pour l'environnement. Ce pesticide représente, malgré tout, un besoin vital pour la production fruitière. Sans cet insecticide, les arbres fruitiers sont infectés par une maladie transmise par un puceron. Certains produits, eh bien, on sera obligé d'abandonner l'arboriculture. Ce serait dommage pour cet agriculteur présent depuis toujours dans la région. La cohabitation entre vergers, produits phytosanitaires et abeilles est plus que possible et il n'est pas incompatible. Le Conseil d'État a jugé cette semaine que les dérogations accordées en 2021 et 2022 concernant l'utilisation de ces néonicotinoïdes...\n",
    "</extrait>\n",
    "<passage climatosceptique>\n",
    "La cohabitation entre vergers, produits phytosanitaires et abeilles est plus que possible et il n'est pas incompatible\n",
    "</passage climatosceptique>\"\"\"\n",
    "    response = await acompletion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"<extrait>\\n{text.strip()}\\n</extrait>\"},\n",
    "            # {\n",
    "            #     \"role\": \"assistant\",\n",
    "            #     \"content\": \"<passage climatosceptique>\",\n",
    "            #     \"prefix\": True,\n",
    "            # },\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        stop=[\"</p\"],  # Same as \"</passage climatosceptique>\" with fewer tokens\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    response_content: str = response.choices[0].message.content\n",
    "    claim = response_content.split(\"<passage climatosceptique>\")[1].strip()\n",
    "\n",
    "    return claim if claim != \"AUCUN\" else None\n",
    "    return MediatreePrediction(\n",
    "        prompt_tokens=response.usage.prompt_tokens,\n",
    "        completion_tokens=response.usage.completion_tokens,\n",
    "        total_tokens=response.usage.total_tokens,\n",
    "        cost=completion_cost(response),\n",
    "        claim_pred=claim if claim != \"AUCUN\" else None,\n",
    "        label_pred=\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "df[\"claims_pred\"] = await tqdm.gather(*[detect_claims(text) for text in df[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.25      0.38        76\n",
      "        True       0.68      0.97      0.80       124\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.75      0.61      0.59       200\n",
      "weighted avg       0.73      0.69      0.64       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"is_contrarian_pred\"] = ~df[\"claims_pred\"].isna()\n",
    "print(classification_report(df[\"is_contrarian_true\"], df[\"is_contrarian_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>quote_true</th>\n",
       "      <th>is_contrarian_true</th>\n",
       "      <th>cards_true</th>\n",
       "      <th>claims_pred</th>\n",
       "      <th>is_contrarian_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bbb629698dfd9319801</th>\n",
       "      <td>Jusqu'au trente septembre, détaille Sofia au q...</td>\n",
       "      <td>Il y a beaucoup de soldats poneys menteurs à t...</td>\n",
       "      <td>False</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>Il y a beaucoup de soldats poneys menteurs à t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0fb8db32982baea27fa4a92220e76331e703d61852c0e8d95550ef6853ffd842</th>\n",
       "      <td>On tente d'échapper à une tempête de pluie d'a...</td>\n",
       "      <td>tempête de pluie d'acide mortelle selon l'inrs...</td>\n",
       "      <td>False</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a9b18aa5c7581c9e02</th>\n",
       "      <td>Les Français n'arrivent pas à se loger, c'est ...</td>\n",
       "      <td>Ça va de l'interdiction des avions d'affaires ...</td>\n",
       "      <td>True</td>\n",
       "      <td>6_proponents_biased</td>\n",
       "      <td>la vérité est qu'une certaine écologie oscille...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b58b532791a33aba423</th>\n",
       "      <td>Le réchauffement climatique a été collecté à G...</td>\n",
       "      <td>on ne peut pas faire le lien directement avec ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2_humans_not_the_cause</td>\n",
       "      <td>on ne peut pas faire le lien directement avec ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>af3a15d298ff642982bcd6c79c21b56623649a140ce3558316dea54ea7ce0f3e</th>\n",
       "      <td>Vous avez ce livre qui est une bande dessinée,...</td>\n",
       "      <td>la crise écologique va rendre la terre inhospi...</td>\n",
       "      <td>False</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72e86031b0690309ec7</th>\n",
       "      <td>Il l'affirme, la piste criminelle est toujours...</td>\n",
       "      <td>les utilisés PFAS dans utilisés la dans fabric...</td>\n",
       "      <td>False</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>« Il n'y a pas de distinction entre les PFAS. ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58feacdc4a4d31023a87bce158ee902d37076d9f5562f3fe41f768ba815b7b6a</th>\n",
       "      <td>Aujourd'hui, ce fameux pacte d'immigration qui...</td>\n",
       "      <td>ce tsunami de normes de contraintes de taxe qu...</td>\n",
       "      <td>True</td>\n",
       "      <td>4_solutions_harmful_unnecessary</td>\n",
       "      <td>le fanatisme vert et le pacte vert qu'il souti...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34308b71c22c78217ec</th>\n",
       "      <td>Avec l'aide de nos fournisseurs, si il s'avère...</td>\n",
       "      <td>l'entreprise n'a pas voulu nous dire combien d...</td>\n",
       "      <td>False</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9ec1c82a2ebfb251527</th>\n",
       "      <td>En France, plusieurs millions de maisons sont ...</td>\n",
       "      <td>le dérèglement climatique phénomène naturel.</td>\n",
       "      <td>False</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>le dérèglement climatique, phénomène naturel</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cdfed233896d49971897df448465dd43b79ae871b33adb5a3a5d464755e8a7cb</th>\n",
       "      <td>Les insectes, non, on pense que c'est la chale...</td>\n",
       "      <td>le progrès sur le réchauffement climatique la ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0_accepted</td>\n",
       "      <td>le progrès sur le réchauffement climatique, la...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text  \\\n",
       "id                                                                                                      \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...  Jusqu'au trente septembre, détaille Sofia au q...   \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...  On tente d'échapper à une tempête de pluie d'a...   \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...  Les Français n'arrivent pas à se loger, c'est ...   \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...  Le réchauffement climatique a été collecté à G...   \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...  Vous avez ce livre qui est une bande dessinée,...   \n",
       "...                                                                                               ...   \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...  Il l'affirme, la piste criminelle est toujours...   \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...  Aujourd'hui, ce fameux pacte d'immigration qui...   \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...  Avec l'aide de nos fournisseurs, si il s'avère...   \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...  En France, plusieurs millions de maisons sont ...   \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...  Les insectes, non, on pense que c'est la chale...   \n",
       "\n",
       "                                                                                           quote_true  \\\n",
       "id                                                                                                      \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...  Il y a beaucoup de soldats poneys menteurs à t...   \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...  tempête de pluie d'acide mortelle selon l'inrs...   \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...  Ça va de l'interdiction des avions d'affaires ...   \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...  on ne peut pas faire le lien directement avec ...   \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...  la crise écologique va rendre la terre inhospi...   \n",
       "...                                                                                               ...   \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...  les utilisés PFAS dans utilisés la dans fabric...   \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...  ce tsunami de normes de contraintes de taxe qu...   \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...  l'entreprise n'a pas voulu nous dire combien d...   \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...       le dérèglement climatique phénomène naturel.   \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...  le progrès sur le réchauffement climatique la ...   \n",
       "\n",
       "                                                    is_contrarian_true  \\\n",
       "id                                                                       \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...               False   \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...               False   \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...                True   \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...                True   \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...               False   \n",
       "...                                                                ...   \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...               False   \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...                True   \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...               False   \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...               False   \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...               False   \n",
       "\n",
       "                                                                         cards_true  \\\n",
       "id                                                                                    \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...                       0_accepted   \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...                       0_accepted   \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...              6_proponents_biased   \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...           2_humans_not_the_cause   \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...                       0_accepted   \n",
       "...                                                                             ...   \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...                       0_accepted   \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...  4_solutions_harmful_unnecessary   \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...                       0_accepted   \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...                       0_accepted   \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...                       0_accepted   \n",
       "\n",
       "                                                                                          claims_pred  \\\n",
       "id                                                                                                      \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...  Il y a beaucoup de soldats poneys menteurs à t...   \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...                                               None   \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...  la vérité est qu'une certaine écologie oscille...   \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...  on ne peut pas faire le lien directement avec ...   \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...                                               None   \n",
       "...                                                                                               ...   \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...  « Il n'y a pas de distinction entre les PFAS. ...   \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...  le fanatisme vert et le pacte vert qu'il souti...   \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...                                               None   \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...       le dérèglement climatique, phénomène naturel   \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...  le progrès sur le réchauffement climatique, la...   \n",
       "\n",
       "                                                    is_contrarian_pred  \n",
       "id                                                                      \n",
       "34a41bf34b35ee91fc147601fb8c21a366a2f568b9060bb...                True  \n",
       "0fb8db32982baea27fa4a92220e76331e703d61852c0e8d...               False  \n",
       "4792f93c6614b1e7ef39e301cc6c1d0f4d3d18b9421cc3a...                True  \n",
       "74c05fdbca4aeffb643abf0de486b57f8299051d4ef71b5...                True  \n",
       "af3a15d298ff642982bcd6c79c21b56623649a140ce3558...               False  \n",
       "...                                                                ...  \n",
       "e7d18bd700a5b9d98f38089975d13d7dc9fa873b15ded72...                True  \n",
       "58feacdc4a4d31023a87bce158ee902d37076d9f5562f3f...                True  \n",
       "6d39a0d45c359fd2183c0f1f001b76c4b60d283240e5c34...               False  \n",
       "0718ef4df3559735ad33436f7e1e39802a71d923cbc0b9e...                True  \n",
       "cdfed233896d49971897df448465dd43b79ae871b33adb5...                True  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the CARDS classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
