{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "\n",
    "def get_label_studio_data(\n",
    "    task_id: Union[int, List[int]] = None,\n",
    "    host: str = None,\n",
    "    token: str = None,\n",
    "    project_id: int = 6,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Requests annotated data from label studio via the API. The request can be limited to reduced data by:\n",
    "    either specifying an task_id (in that case only data from successive tasks will be returned);\n",
    "    or by specifying a list of task_ids (in that case data will be recovered for those tasks).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task_id: Union[int, List[int]]\n",
    "        A either an integer task_id (in that case only data from successive tasks will be returned)\n",
    "        or a list of task_ids (in that case data will be recovered for those tasks).\n",
    "    host: str = None\n",
    "        Hostname for the Label Studio endpoint. If None, then the value will have to be set via the \n",
    "        LABEL_STUDIO_HOST environment variable.\n",
    "    token: str = None\n",
    "        API token to connect to the Label Studio endpoint. If None, then the value will have to be set via the \n",
    "        LABEL_STUDIO_TOKEN environment variable.\n",
    "    project_id: int = 6\n",
    "        Project id as defined in Label Studio.\n",
    "    \"\"\"\n",
    "    if token is None:\n",
    "        token = os.getenv(\"LABEL_STUDIO_TOKEN\")\n",
    "    if host is None:\n",
    "        host = os.getenv(\"LABEL_STUDIO_HOST\")\n",
    "\n",
    "    assert token is not None, (\n",
    "        \"`token` needs to be set as function argument or as the environment variable `LABEL_STUDIO_TOKEN`.\",\n",
    "        \"In case both are set, the function argument will override the environment variable.\",\n",
    "    )\n",
    "    assert host is not None, (\n",
    "        \"`host` needs to be set as function argument or as the environment variable `LABEL_STUDIO_HOST`.\",\n",
    "        \"In case both are set, the function argument will override the environment variable.\",\n",
    "    )\n",
    "    if isinstance(task_id, int):\n",
    "        url_query = f\"ids[]>{task_id}&\"\n",
    "    elif isinstance(task_id, list):\n",
    "        url_query = \"\".join([f\"ids[]>{_task_id}&\" for _task_id in task_id])\n",
    "    else:\n",
    "        url_query = \"\"\n",
    "    url = f\"https://{host}/api/projects/{project_id}/export?{url_query}exportType=JSON\"\n",
    "    headers = {\"Authorization\": f\"Token {token}\"}\n",
    "    response = requests.get(url=url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_label_studio_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'week_number': 2}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_week_number(record):\n",
    "    format_str = \"%Y-%m-%dT%H:%M:%S\"\n",
    "    if len(record[\"data\"][\"item\"][\"start\"]) > 19:\n",
    "        format_str = format_str + \"%z\"\n",
    "    week_number = (\n",
    "        datetime.strptime(record[\"data\"][\"item\"][\"start\"], format_str)\n",
    "        .isocalendar()\n",
    "        .week\n",
    "    )\n",
    "    return {\"week_number\": week_number}\n",
    "\n",
    "\n",
    "get_week_number(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations_from_record(record: dict) -> dict:\n",
    "    cards_claims = []\n",
    "    cards_labels = []\n",
    "    misinformation_claims = []\n",
    "    comments = []\n",
    "    misinformation_bool = False\n",
    "    for annotation_session in record[\"annotations\"]:\n",
    "        if annotation_session[\"was_cancelled\"]:\n",
    "            continue\n",
    "        else:\n",
    "            for annotation_record in annotation_session[\"result\"]:\n",
    "                if annotation_record[\"from_name\"] == \"choice\":\n",
    "                    misinformation_bool = (\n",
    "                        \"Correct\" in annotation_record[\"value\"][\"choices\"]\n",
    "                    )\n",
    "                elif annotation_record[\"from_name\"] == \"cards\":\n",
    "                    cards_claims.append(\n",
    "                        {\n",
    "                            \"text\": annotation_record[\"value\"][\"text\"],\n",
    "                            \"labels\": annotation_record[\"value\"][\"labels\"],\n",
    "                        }\n",
    "                    )\n",
    "                    cards_labels.extend(annotation_record[\"value\"][\"labels\"])\n",
    "                elif annotation_record[\"from_name\"] == \"misinformation\":\n",
    "                    misinformation_claims.append(\n",
    "                        {\n",
    "                            \"text\": annotation_record[\"value\"][\"text\"],\n",
    "                            \"labels\": annotation_record[\"value\"][\"labels\"],\n",
    "                        }\n",
    "                    )\n",
    "                elif annotation_record[\"from_name\"] == \"comments\":\n",
    "                    comments.append(\"\\n\".join(annotation_record[\"value\"][\"text\"]))\n",
    "        return {\n",
    "            \"misinformation\": misinformation_bool,\n",
    "            \"cards_claims\": cards_claims,\n",
    "            \"misinformation_claims\": misinformation_claims,\n",
    "            \"comments\": comments,\n",
    "        }\n",
    "    return {\n",
    "        \"misinformation\": False,\n",
    "        \"cards_labels\": [],\n",
    "        \"cards_claims\": [],\n",
    "        \"misinformation_claims\": [],\n",
    "        \"comments\": comments,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'misinformation': False,\n",
       " 'cards_claims': [],\n",
       " 'misinformation_claims': [],\n",
       " 'comments': ['Gros faux-positif']}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_annotations_from_record(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_studio_id': 1810,\n",
       " 'id': '382b3d21738c3d0e33d751bd3a74953d648f93490b37554641484c77c611729a',\n",
       " 'day': 10,\n",
       " 'year': 2025,\n",
       " 'month': 1,\n",
       " 'start': '2025-01-10T06:06:00+00:00',\n",
       " 'channel': 'itele',\n",
       " 'plaintext': \"pour l' instant on ne sait pas vraiment si c' est un un incendiaire qui s' est confirmée en fait que ce soit un incendiaire ou pas voilà l' enquête dira si ce sont des incendies volontaires mais il y a des y a des suspicions c' est ce que vous nous dites merci beaucoup ramzy marzouki joe biden de x et le changement climatique m qui explique ces incendie michel chevalet c' est le changement climatique ces incendies un je vous rappelle tout de même pas ils sont dix fois où il y en a conscience que j' ai un sécheresse de vent violent trois maquis airs maquis secs qui et aide maquis les troupes qui aide sujets les donc taupes dû être celle que vous allez voir c' est un cocktail d' état alors le changement climatique le réchauffement climatique oubliez les un degré cinq en californie on va plutôt vers deux c' est un facteur aggravant mais ce n' est pas la cause de de ce départ de feu merci beaucoup merci beaucoup michel le renvoi par l' algérie d' un de ses ressortissants est la dernière illustration des relations déplorables entre paris et alger ce qu' emmanuel macron doit macron durcir doit le durcir ton le vis-à-vis ton vis-à-vis de l' algérie thomas bonnet en tout cas on voit que le discours timide de d' emmanuel macron ne porte pas ses fruits il a à peine évoqué le cas de boualem sansal en expliquant que l' algérie se déshonore en détenant de manière totalement arbitraire l' écrivain il y a déjà eu des réactions ex est incroyable de la part du pouvoir algérien et de certains médias on a l' impression d' une certaine manière quéménès macron a peur de froisser l' algérie il faut se replonger dans l' interview qu' il avait accordé à l' écrivain kamel daoud en deux mille vingt-deux il disait prendre la parole la sur parole l' sur algérie l' c' algérie est potentiellement périlleux mais indispensable à la question est ce que l' algérie c' est un risque politique il dit oui à l' est et le candidat de deux mille dix-sept que je l' étais que j' étais l' avait sans doute sous-estimée mais aujourd' hui je suis de détacher de cela dont acte parmi les leviers diplomatiques il y a évidemment l' accord franco-algérien de mille neuf cent soixante-huit il est peut-être temps de réviser ses et accorde c' est en tout cas ce que demande un certain nombre de responsables politiques de droite merci beaucoup thomas et on va en parler dans un instant dans le débat de la matinale a tout de suite <unk>\",\n",
       " 'model_name': 'ft:gpt-4o-mini-2024-07-18:personal::B1xWiJRm',\n",
       " 'channel_name': 'itele',\n",
       " 'model_reason': \"Le texte affirme clairement que le changement climatique n'est pas la cause des incendies, mais un facteur aggravant, ce qui contredit le consensus scientifique sur le rôle du changement climatique dans l'augmentation de la fréquence et de l'intensité des incendies.\",\n",
       " 'model_result': 10,\n",
       " 'channel_title': 'CNews',\n",
       " 'url_mediatree': 'https://keywords.mediatree.fr/player/?fifo=itele&start_cts=1736489160&end_cts=1736489280&position_cts=1736489160',\n",
       " 'channel_program': 'Information en continu',\n",
       " 'plaintext_whisper': \"On ne sait pas vraiment si c'est un incendiaire, si c'est confirmé en fait que ce soit un incendiaire ou pas. Voilà, l'enquête dira si ce sont des incendies volontaires, mais il y a des suspicions, c'est ce que vous nous dites. Merci beaucoup Ramzi Maloukhi. Joe Biden dit que c'est le changement climatique qui explique ces incendies. Michel Chevalet, c'est le changement climatique ? Ces incendies, je vous rappelle, ce n'est même pas un incendie, il faut bien avoir conscience que c'est, un, sécheresse, deux, fonds violents, trois, air sec, et maquis, maquis qui est de l'étoupe. Il suffisait donc d'une étincelle, vous allez voir, donc c'est un cocktail d'étincelles. Alors, le changement, il y a changement climatique, le réchauffement climatique, oubliez les 1,5° en Californie, on va plutôt vers 2, c'est un facteur aggravant, mais ce n'est pas la cause de ce départ de feu. Merci beaucoup, merci beaucoup Michel. Le renvoi par l'Algérie d'un de ses ressortissants est la dernière illustration des relations déplorables entre Paris et Alger. Est-ce qu'Emmanuel Macron doit durcir le temps vis-à-vis de l'Algérie ? Thomas Bonnet. En tout cas, on voit que le discours timide d'Emmanuel Macron ne porte pas ses fruits. Il a à peine évoqué le cas de Boalem Sansal en expliquant que l'Algérie se déshonore en détenant de manière totalement arbitraire l'écrivain. Il y a déjà eu des réactions incroyables de la part du pouvoir algérien et de certains médias. On a l'impression, d'une certaine manière, qu'Emmanuel Macron a peur de froisser l'Algérie. Il faut se replonger dans l'interview qu'il avait accordée à l'écrivain Kamel Daoud en 2022. Il disait « Prendre la parole sur l'Algérie, c'est potentiellement périlleux, mais indispensable. » Et à la question « Est-ce que l'Algérie, c'est un risque politique ? », il dit « Oui, elle l'est. » Et le candidat de 2017 que j'étais l'avait sans doute sous-estimé. Mais aujourd'hui, je suis détaché de cela. Dont acte, parmi les leviers diplomatiques, il y a évidemment l'accord franco-algérien de 1968. Il est peut-être temps de réviser cet accord. C'est en tout cas ce que demandent un certain nombre de responsables politiques de droite. Merci beaucoup Thomas. On va en parler dans un instant dans le débat de la matinale. À tout de suite.\\n\",\n",
       " 'channel_program_type': 'Information en continu',\n",
       " 'week_number': 2,\n",
       " 'misinformation': False,\n",
       " 'cards_claims': [],\n",
       " 'misinformation_claims': [],\n",
       " 'comments': ['Gros faux-positif']}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_record(record):\n",
    "    record_data = {\"label_studio_id\": record[\"id\"]}\n",
    "    record_data.update(record[\"data\"][\"item\"])\n",
    "    record_data.update(get_week_number(record=record))\n",
    "    record_data.update(get_annotations_from_record(record=record))\n",
    "    return record_data\n",
    "\n",
    "\n",
    "process_record(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 529\n"
     ]
    }
   ],
   "source": [
    "parsed_data = []\n",
    "parsed_data_test = []\n",
    "for record in data:\n",
    "    parsed_record = process_record(record)\n",
    "    if hash(str(parsed_record[\"week_number\"]) + str(parsed_record[\"year\"])) % 4:\n",
    "        parsed_data.append(parsed_record)\n",
    "    else:\n",
    "        parsed_data_test.append(parsed_record)\n",
    "print(len(parsed_data_test), len(parsed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_list(parsed_data),\n",
    "        \"test\": Dataset.from_list(parsed_data_test),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label_studio_id', 'id', 'day', 'year', 'month', 'start', 'channel', 'plaintext', 'model_name', 'channel_name', 'model_reason', 'model_result', 'channel_title', 'url_mediatree', 'channel_program', 'plaintext_whisper', 'channel_program_type', 'week_number', 'misinformation', 'cards_claims', 'misinformation_claims', 'comments'],\n",
       "        num_rows: 529\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label_studio_id', 'id', 'day', 'year', 'month', 'start', 'channel', 'plaintext', 'model_name', 'channel_name', 'model_reason', 'model_result', 'channel_title', 'url_mediatree', 'channel_program', 'plaintext_whisper', 'channel_program_type', 'week_number', 'misinformation', 'cards_claims', 'misinformation_claims', 'comments'],\n",
       "        num_rows: 137\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add section where you get the old dataset and the data contained in it, \n",
    "# append the data that is not already present in the dataset \n",
    "# before pushing to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075b1ae144c747739ca822881b94a01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdede9eb3c3b40f6801e467e9d954683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e32d42043494fc48b7974d6d624a736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e699bad06ef64e0192d40417a6664c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/DataForGood/climateguard/commit/4904c03d4283a89a69fa998ae6d97a970bb1574f', commit_message='Upload dataset', commit_description='', oid='4904c03d4283a89a69fa998ae6d97a970bb1574f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/DataForGood/climateguard', endpoint='https://huggingface.co', repo_type='dataset', repo_id='DataForGood/climateguard'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"DataForGood/climateguard\", private=False, token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
