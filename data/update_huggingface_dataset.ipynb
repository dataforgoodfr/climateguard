{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "\n",
    "def get_label_studio_data(\n",
    "    task_id: Union[int, List[int]] = None,\n",
    "    host: str = None,\n",
    "    token: str = None,\n",
    "    project_id: int = 6,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Requests annotated data from label studio via the API. The request can be limited to reduced data by:\n",
    "    either specifying an task_id (in that case only data from successive tasks will be returned);\n",
    "    or by specifying a list of task_ids (in that case data will be recovered for those tasks).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task_id: Union[int, List[int]]\n",
    "        A either an integer task_id (in that case only data from successive tasks will be returned)\n",
    "        or a list of task_ids (in that case data will be recovered for those tasks).\n",
    "    host: str = None\n",
    "        Hostname for the Label Studio endpoint. If None, then the value will have to be set via the \n",
    "        LABEL_STUDIO_HOST environment variable.\n",
    "    token: str = None\n",
    "        API token to connect to the Label Studio endpoint. If None, then the value will have to be set via the \n",
    "        LABEL_STUDIO_TOKEN environment variable.\n",
    "    project_id: int = 6\n",
    "        Project id as defined in Label Studio.\n",
    "    \"\"\"\n",
    "    if token is None:\n",
    "        token = os.getenv(\"LABEL_STUDIO_TOKEN\")\n",
    "    if host is None:\n",
    "        host = os.getenv(\"LABEL_STUDIO_HOST\")\n",
    "\n",
    "    assert token is not None, (\n",
    "        \"`token` needs to be set as function argument or as the environment variable `LABEL_STUDIO_TOKEN`.\",\n",
    "        \"In case both are set, the function argument will override the environment variable.\",\n",
    "    )\n",
    "    assert host is not None, (\n",
    "        \"`host` needs to be set as function argument or as the environment variable `LABEL_STUDIO_HOST`.\",\n",
    "        \"In case both are set, the function argument will override the environment variable.\",\n",
    "    )\n",
    "    if isinstance(task_id, int):\n",
    "        url_query = f\"ids[]>{task_id}&\"\n",
    "    elif isinstance(task_id, list):\n",
    "        url_query = \"\".join([f\"ids[]>{_task_id}&\" for _task_id in task_id])\n",
    "    else:\n",
    "        url_query = \"\"\n",
    "    url = f\"https://{host}/api/projects/{project_id}/export?{url_query}exportType=JSON\"\n",
    "    headers = {\"Authorization\": f\"Token {token}\"}\n",
    "    response = requests.get(url=url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_label_studio_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'week_number': 40}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_week_number(record):\n",
    "    format_str = \"%Y-%m-%dT%H:%M:%S\"\n",
    "    if len(record[\"data\"][\"item\"][\"start\"]) > 19:\n",
    "        format_str = format_str + \"%z\"\n",
    "    week_number = (\n",
    "        datetime.strptime(record[\"data\"][\"item\"][\"start\"], format_str)\n",
    "        .isocalendar()\n",
    "        .week\n",
    "    )\n",
    "    return {\"week_number\": week_number}\n",
    "\n",
    "\n",
    "get_week_number(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations_from_record(record: dict) -> dict:\n",
    "    cards_claims = []\n",
    "    cards_labels = []\n",
    "    misinformation_claims = []\n",
    "    comments = []\n",
    "    misinformation_bool = False\n",
    "    for annotation_session in record[\"annotations\"]:\n",
    "        if annotation_session[\"was_cancelled\"]:\n",
    "            continue\n",
    "        else:\n",
    "            for annotation_record in annotation_session[\"result\"]:\n",
    "                if annotation_record[\"from_name\"] == \"choice\":\n",
    "                    misinformation_bool = (\n",
    "                        \"Correct\" in annotation_record[\"value\"][\"choices\"]\n",
    "                    )\n",
    "                elif annotation_record[\"from_name\"] == \"cards\":\n",
    "                    cards_claims.append(\n",
    "                        {\n",
    "                            \"text\": annotation_record[\"value\"][\"text\"],\n",
    "                            \"labels\": annotation_record[\"value\"][\"labels\"],\n",
    "                        }\n",
    "                    )\n",
    "                    cards_labels.extend(annotation_record[\"value\"][\"labels\"])\n",
    "                elif annotation_record[\"from_name\"] == \"misinformation\":\n",
    "                    misinformation_claims.append(\n",
    "                        {\n",
    "                            \"text\": annotation_record[\"value\"][\"text\"],\n",
    "                            \"labels\": annotation_record[\"value\"][\"labels\"],\n",
    "                        }\n",
    "                    )\n",
    "                elif annotation_record[\"from_name\"] == \"comments\":\n",
    "                    comments.append(\"\\n\".join(annotation_record[\"value\"][\"text\"]))\n",
    "        return {\n",
    "            \"misinformation\": misinformation_bool,\n",
    "            \"cards_claims\": cards_claims,\n",
    "            \"misinformation_claims\": misinformation_claims,\n",
    "            \"comments\": comments,\n",
    "        }\n",
    "    return {\n",
    "        \"misinformation\": False,\n",
    "        \"cards_labels\": [],\n",
    "        \"cards_claims\": [],\n",
    "        \"misinformation_claims\": [],\n",
    "        \"comments\": comments,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'misinformation': True,\n",
       " 'cards_claims': [{'text': '', 'labels': ['2. Humans are not the cause']}],\n",
       " 'misinformation_claims': [],\n",
       " 'comments': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_annotations_from_record(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_studio_id': 1604,\n",
       " 'id': '712ded15b00734e052d1e2f5dd23a73a2e6d4ff2cbd31703d5efe29730a5eeee',\n",
       " 'day': 2,\n",
       " 'year': 2023,\n",
       " 'month': 10,\n",
       " 'start': '2023-10-02T16:46:00',\n",
       " 'channel': 'itele',\n",
       " 'plaintext': \"des anomalies l'europe centrale la france mais aussi au niveau global les plus jeunes un chien les hausses les anomalies et les matches à trois degrés de plus cette année il y a aussi une qui ligne a aussi qui un accélère maintenant ces prochains mois c'est juste un petit à petit les prévisions saisonnières pour le mois d'octobre ma vie ce chantier vingt-six plus chaudes jamais cessé surtout la france aussi l'italie l'allemagne norvège plouguenast accès c'est d'accord on va juste prendre de réaction de nos invités puissent vous demanderez peut-être si on est là vraiment dans les conséquences du réchauffement climatique tels qu'on le le phage gèrent des conséquences de de nos actions sur le réchauffement climatique tels qu'on les imagine on les on envisage les ivan envisage rioufol ivan est rioufol est ce que que vous faites partie de ceux qui disent attention stop maintenant il va falloir vraiment faire quelque chose il faut faire quelque chose sans doute à l'évidence bien que encore une fois je ne sais pas été totalement convaincus par la responsabilité totale de l'homme dans le réchauffement climatique j'entends bien que l'homme a une responsabilité sans doute dans le réchauffement climatique mais l'histoire du emmanuel climat le roy ladurie a montré dans ses livres est une succession de refroidir au refroidissement et de réchauffement en mille sept cent neuf le lacet lahcen gelé en mille sept cent quatre-vingt douze je crois euh il y avait quarante degrés à paris\",\n",
       " 'model_name': 'ft:gpt-4o-mini-2024-07-18:personal::B1xWiJRm',\n",
       " 'channel_name': 'itele',\n",
       " 'model_reason': '',\n",
       " 'model_result': 10,\n",
       " 'channel_title': 'CNews',\n",
       " 'url_mediatree': '',\n",
       " 'channel_program': 'Information en continu',\n",
       " 'plaintext_whisper': 'Des anomalies en Europe centrale, en France, mais aussi au niveau global. Les plus jeunes constatent les hausses des températures, avec des anomalies atteignant trois degrés de plus cette année. Il y a aussi une ligne qui s\\'accélère maintenant. Ces prochains mois, les prévisions saisonnières pour le mois d\\'octobre annoncent des températures plus chaudes que jamais, surtout en France, en Italie, en Allemagne et en Norvège. D\\'accord, nous allons juste prendre la réaction de nos invités. Vous vous demanderez peut-être si nous sommes vraiment face aux conséquences du réchauffement climatique, telles qu\\'on les imagine. Ivan Rioufol, est-ce que vous faites partie de ceux qui disent : \"Attention, stop maintenant, il va falloir vraiment faire quelque chose\" ? Il faut faire quelque chose, sans doute, à l\\'évidence. Bien que, encore une fois, je ne sais pas été totalement convaincus par la responsabilité totale de l\\'homme dans le réchauffement climatique. J\\'entends bien que l\\'homme a une responsabilité, sans doute, dans le réchauffement climatique, mais l\\'historien Emmanuel Le Roy Ladurie a montré dans ses livres qu\\'il y a eu une succession de refroidissements et de réchauffements. En 1709, le lac était gelé, et en 1792, il y avait quarante degrés à Paris.',\n",
       " 'channel_program_type': '',\n",
       " 'week_number': 40,\n",
       " 'misinformation': True,\n",
       " 'cards_claims': [{'text': '', 'labels': ['2. Humans are not the cause']}],\n",
       " 'misinformation_claims': [],\n",
       " 'comments': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_record(record):\n",
    "    record_data = {\"label_studio_id\": record[\"id\"]}\n",
    "    record_data.update(record[\"data\"][\"item\"])\n",
    "    record_data.update(get_week_number(record=record))\n",
    "    record_data.update(get_annotations_from_record(record=record))\n",
    "    return record_data\n",
    "\n",
    "\n",
    "process_record(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 568\n"
     ]
    }
   ],
   "source": [
    "parsed_data = []\n",
    "parsed_data_test = []\n",
    "for record in data:\n",
    "    parsed_record = process_record(record)\n",
    "    if hash(str(parsed_record[\"week_number\"]) + str(parsed_record[\"year\"])) % 4:\n",
    "        parsed_data.append(parsed_record)\n",
    "    else:\n",
    "        parsed_data_test.append(parsed_record)\n",
    "print(len(parsed_data_test), len(parsed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_list(parsed_data),\n",
    "        \"test\": Dataset.from_list(parsed_data_test),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label_studio_id', 'id', 'day', 'year', 'month', 'start', 'channel', 'plaintext', 'model_name', 'channel_name', 'model_reason', 'model_result', 'channel_title', 'url_mediatree', 'channel_program', 'plaintext_whisper', 'channel_program_type', 'week_number', 'misinformation', 'cards_claims', 'misinformation_claims', 'comments'],\n",
       "        num_rows: 568\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label_studio_id', 'id', 'day', 'year', 'month', 'start', 'channel', 'plaintext', 'model_name', 'channel_name', 'model_reason', 'model_result', 'channel_title', 'url_mediatree', 'channel_program', 'plaintext_whisper', 'channel_program_type', 'week_number', 'misinformation', 'cards_claims', 'misinformation_claims', 'comments'],\n",
       "        num_rows: 173\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add section where you get the old dataset and the data contained in it, \n",
    "# append the data that is not already present in the dataset \n",
    "# before pushing to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aad5045c0cd4cbaab3f74e34474cc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd2453b154444e79a7b65fde2743e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ef200867de4104a70bc70bd805a3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ccc0336b4c4c0c9bea67c629ff280d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/DataForGood/climateguard/commit/c81c932a5236b348971f5ec5d48c2939ff058a8d', commit_message='Upload dataset', commit_description='', oid='c81c932a5236b348971f5ec5d48c2939ff058a8d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/DataForGood/climateguard', endpoint='https://huggingface.co', repo_type='dataset', repo_id='DataForGood/climateguard'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"DataForGood/climateguard\", private=False, token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
