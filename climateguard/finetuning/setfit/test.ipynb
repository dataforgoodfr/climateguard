{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel\n",
    "\n",
    "# Download from the ðŸ¤— Hub\n",
    "model = SetFitModel.from_pretrained(\"gmguarino/multilingual-e5-base-climateguard\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 512\n",
    "CHUNK_OVERLAP = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    ")\n",
    "\n",
    "dataset_id = \"DataForGood/climateguard\"\n",
    "# Load raw dataset\n",
    "dataset = load_dataset(dataset_id, split=\"test\")\n",
    "\n",
    "records = []\n",
    "for idx, record in enumerate(dataset):\n",
    "    chunks = splitter.split_text(record[\"plaintext\"].lower().replace(\".\", \"\").replace(\",\", \"\"))\n",
    "    for chunk in chunks:\n",
    "        records.append(\n",
    "            {\n",
    "                \"id\": idx,\n",
    "                \"text\": chunk,\n",
    "                \"label\": int(record[\"misinformation\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "claims_dataset = Dataset.from_pandas(pd.DataFrame.from_records(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dba1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize helper function\n",
    "# def tokenize(batch):\n",
    "#     return tokenizer(\n",
    "#         batch[\"text\"],\n",
    "#         # padding=\"max_length\",\n",
    "#         truncation=True,\n",
    "#         max_length=CHUNK_SIZE,\n",
    "#         return_tensors=\"pt\",\n",
    "#     )\n",
    "\n",
    "\n",
    "def format_labels(example):\n",
    "    return {\"label\": int(example[\"label\"])}\n",
    "\n",
    "\n",
    "claims_dataset = claims_dataset.map(format_labels, batched=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "# client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "_system_prompt = \"\"\"You are an assistant helping editors to moderate TV and radio content.\n",
    "You will be provided with a transcript delimited by triple backticks.\n",
    "Bear in mind that the transcript may be missing punctuation and may be of very low quality, with incorrect vocabulary, cuts in the wrong places, or may include some phonetic transcription.\n",
    "\n",
    "Does the text promote climate change misinformation that undermines well-established scientific consensus, such as denying the existence of climate change or the factors that contribute to it ?\n",
    "\n",
    "Answer just a number on a scale of 0 - does not promote - to 10 - certainly promotes.\n",
    "\n",
    "text:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93708d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_response(response: str):\n",
    "    \"\"\"Parse response containing only a score.\"\"\"\n",
    "    match = re.match(r\"^[^\\d]*(\\d+)\", response)\n",
    "    if match:\n",
    "        score = int(match.group(1))  # Extract score as an integer\n",
    "    else:\n",
    "        score = 0\n",
    "    return int(score >= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "predictions = []\n",
    "openai_predictions = []\n",
    "labels = []\n",
    "outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for record in tqdm(claims_dataset):\n",
    "        # prompt = _system_prompt + f\" '''{record[\"text\"]}'''\"\n",
    "        # messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "        output = model.predict_proba(record[\"text\"]).cpu()\n",
    "        prediction = model(record[\"text\"])\n",
    "        # response = client.chat.completions.create(\n",
    "        #     model=\"ft:gpt-4o-mini-2024-07-18:personal::B1xWiJRm\",\n",
    "        #     messages=messages,\n",
    "        #     temperature=0,\n",
    "        # )\n",
    "        # result = response.choices[0].message.content.strip()\n",
    "        outputs.append(output.numpy())\n",
    "        predictions.append(prediction)\n",
    "        # openai_predictions.append(parse_response(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2afd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = claims_dataset.to_pandas()\n",
    "df[\"predictions\"] = predictions\n",
    "# df[\"openai_predictions\"] = openai_predictions\n",
    "df = df.groupby([\"id\"]).agg(\"max\").drop(columns=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"setfit\")\n",
    "print(classification_report(df.label, df.predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(outputs, columns=[\"logit_0\", \"logit_1\"]).plot(kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecdf754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"OpenAI\")\n",
    "print(classification_report(df.label, df.openai_predictions))\n",
    "print(\"setfit\")\n",
    "print(classification_report(df.label, df.predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.openai_predictions.value_counts())\n",
    "display(df.predictions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132281a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1e49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b2543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
