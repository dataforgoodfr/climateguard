{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11be3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"DataForGood/climateguard\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4e9d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_studio_id': 2160,\n",
       " 'id': 'f5d30bfcb029eb6de736353e72d9bdb987e1a70b3849eb3f3cdb536512862567',\n",
       " 'day': 7,\n",
       " 'year': 2025,\n",
       " 'month': 3,\n",
       " 'start': '2025-03-07T11:24:00+00:00',\n",
       " 'channel': 'rmc',\n",
       " 'plaintext': \"alors on vous entend super mal donc je vous disais vous passez tous les jours à côté de changé la bad not les e allons aujourd' hui un niveau infrastructure si on ne veut pas de grosses grosses entreprises qui partiront comme des entreprises pharmaceutiques convoqué dans le cadre qui abordent aujourd' hui dès huit mille salariés pas de bêtise ça rit ça brise la ligne malheureusement allez sont allez mauvais un on enjeu est un économique enjeu très économique très fort et on peut parvenir on ne peut pas revenir en arrière on est désolés favorisant la ligne était trop mauvais on intervenait avec louis alors de senlis en haute-garonne il est conducteur d' engins bonjour louis un beau jour toute l' équipe conducteurs d' engins vous étiez sur euh sur le chantier d' autoroute justement louis non pas tout à fait sur des plateformes je produis des produits euh justement pour faire des des secousses on a tout ce qui ce est qui démolition est j' aurais démolition pu j' traiter aurais mais bon pu je traiter connais mais bon je connais je connais le métier moi seule j' appelais surtout pour dire oui à ce point là où on est aujourd' hui il faut finir le chantier le prix que ça à côté et le prix que ça va coûter pour sécuriser le chantier il faut absolument le terminer et louis mais vous est que le gouvernement réfléchira à deux fois euh eux la prochaine fois avant de avant de créer une autoroute justement parce que là on voit que la polémique savais que cela ça engendre merci d' avoir avoir été avec nous nous rémy barret et non de cerner le son ça me tient à côté ou de l' autre c' est un fiasco mais elle est la seule leçon à apprendre c' est qu' on doit arrêter de se soumettre à l' extrême gauche et au terrorisme écologique il va dire ce rapport les méchants très même darmanin c' est du terrorisme écologique c' est toujours les mêmes personnes qui sont des marginaux ce sont des marchés un juge <unk> ancien juge juliette un jugement je mets la plaque euh c' est un juge qui l' ia\",\n",
       " 'model_name': 'ft:gpt-4o-mini-2024-07-18:personal::B1xWiJRm',\n",
       " 'channel_name': 'rmc',\n",
       " 'model_reason': 'Le texte mentionne explicitement le \"terrorisme écologique\" et qualifie les personnes qui s\\'opposent à certaines pratiques comme étant des \"marginaux\", ce qui constitue une forme de désinformation sur le climat en minimisant les préoccupations légitimes concernant l\\'environnement et en dénigrant ceux qui militent pour des actions contre le changement climatique.',\n",
       " 'model_result': 10,\n",
       " 'channel_title': 'RMC',\n",
       " 'url_mediatree': 'https://keywords.mediatree.fr/player/?fifo=rmc&start_cts=1741346640&end_cts=1741346760&position_cts=1741346640',\n",
       " 'channel_program': 'Les grandes gueules',\n",
       " 'plaintext_whisper': \"Donc vous me disiez que vous passez tous les jours à côté du chantier. L'Union, si on l'abandonnait, alors aujourd'hui au niveau infrastructures, si on ne les encadre pas, il y a des grosses entreprises qui partiront, comme des entreprises pharmaceutiques, comme Pierre-Jean Sabra, qui alors d'aujourd'hui font aux alentours des 8 000 salariés, si je ne dis pas de bêtises. Fabrice, la ligne, malheureusement, elle est trop mauvaise. Il y a un enjeu économique très fort qui est lancé et on ne peut pas revenir en arrière. On est désolé Fabrice, la ligne était trop mauvaise. On va terminer avec Louis, de Saint-Lys, en Haute-Garonne. Il est conducteur d'engin. Bonjour Louis. Bonjour Estelle, bonjour toute l'équipe. Conducteur d'engin, vous étiez sur le chantier de l'autoroute justement Louis ? Non, pas tout à fait. Je travaille sur des plateformes. Je produis des produits justement pour faire des sous-couches et tout ça. Je récupère des bétons, tout ce qui est l'émolution, je le traite. Mais bon, je connais le métier de terrassement et tout ça. Et moi, j'appelais surtout pour dire que oui, à ce point-là où on est aujourd'hui, il faut finir le chantier avec le prix que ça a coûté et le prix que ça va coûter pour sécuriser le chantier. Il faut absolument le terminer. Oui, mais peut-être que le gouvernement réfléchira deux fois la prochaine fois avant de créer une autoroute justement. Parce que là, on voit toute la polémique que ça engendre. Merci beaucoup Louis d'avoir été avec nous. Au moins, on en tire des leçons. Parce que d'un côté ou de l'autre, c'est un fiasco. Non, mais la seule leçon à apprendre, c'est qu'on doit arrêter de se soumer à l'extrême gauche et au terrorisme écologique. Oui, mais non, Juliette ne peut pas dire ça. Les aéroports, mais je peux le dire parce que c'est vrai. Même Darmanin le disait à l'époque. C'est du terrorisme écologique, c'est toujours les mêmes personnes. Ce sont des marginaux. Non, mais là c'est un juge. C'est un juge, Juliette.\\n\",\n",
       " 'channel_program_type': 'Information - Magazine',\n",
       " 'week_number': 10,\n",
       " 'misinformation': False,\n",
       " 'cards_claims': [{'labels': ['4_solutions_are_ineffective_or_harmful'],\n",
       "   'text': \"si on l'abandonnait, alors aujourd'hui au niveau infrastructures, si on ne les encadre pas, il y a des grosses entreprises qui partiront, comme des entreprises pharmaceutiques, comme Pierre-Jean Sabra, qui alors d'aujourd'hui font aux alentours des 8 000 salariés\"},\n",
       "  {'labels': ['4_solutions_are_ineffective_or_harmful'],\n",
       "   'text': \"à ce point-là où on est aujourd'hui, il faut finir le chantier avec le prix que ça a coûté et le prix que ça va coûter pour sécuriser le chantier. Il faut absolument le terminer\"},\n",
       "  {'labels': ['4_solutions_are_ineffective_or_harmful'],\n",
       "   'text': \"qu'on doit arrêter de se soumer à l'extrême gauche et au terrorisme écologique\"},\n",
       "  {'labels': ['6_advocates_are_biased'],\n",
       "   'text': \"C'est du terrorisme écologique, c'est toujours les mêmes personnes. Ce sont des marginaux\"}],\n",
       " 'misinformation_claims': [],\n",
       " 'comments': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0947121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309b470cd8e54f68a0851099f87a1c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "\n",
    "model_lora, tokenizer_lora = load(\n",
    "    path_or_hf_repo=\"microsoft/Phi-3-mini-4k-instruct\", \n",
    "    adapter_path=\"adapters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89edd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": example[\"plaintext\"]}\n",
    "]\n",
    "\n",
    "prompt = tokenizer_lora.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "response = generate(\n",
    "    model_lora,\n",
    "    tokenizer_lora,\n",
    "    prompt=prompt,\n",
    "    max_tokens=1000,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac3a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "def parse_json(text):\n",
    "    pattern = r'\\{.*?\\}'  # Matches JSON-like objects\n",
    "\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(0)\n",
    "        try:\n",
    "            json_obj = json.loads(json_str)  # Properly parse the JSON\n",
    "            return json_obj\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Cannot decode JSON\")\n",
    "            return None\n",
    "    print(\"No match found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60682ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355c209755344cb58f05d2cbb51dad26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m prompt \u001b[38;5;241m=\u001b[39m tokenizer_lora\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m response \u001b[38;5;241m=\u001b[39m generate(\n\u001b[1;32m     13\u001b[0m     model_lora,\n\u001b[1;32m     14\u001b[0m     tokenizer_lora,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m predictions\u001b[38;5;241m.\u001b[39mappend(parse_json(response)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mparse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmisinformation\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for example in tqdm(dataset):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": example[\"plaintext\"]}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer_lora.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "    response = generate(\n",
    "        model_lora,\n",
    "        tokenizer_lora,\n",
    "        prompt=prompt,\n",
    "        max_tokens=1024,\n",
    "        verbose=False\n",
    "    )\n",
    "    predictions.append(parse_json(response)[\"score\"] if parse_json(response) else 0)\n",
    "    labels.append(int(example[\"misinformation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26d54c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [int(label) * 10 for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97be389e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.78      0.73        67\n",
      "          10       0.48      0.37      0.42        38\n",
      "\n",
      "    accuracy                           0.63       105\n",
      "   macro avg       0.58      0.57      0.57       105\n",
      "weighted avg       0.61      0.63      0.62       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25f52706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 10]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7f6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
